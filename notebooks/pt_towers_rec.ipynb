{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchmetrics\n",
    "\n",
    "from deeprec.torch.trainer import Trainer, set_device\n",
    "from deeprec import ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['title_emb_size', 'string_na', 'genres', 'ages', 'occupations', 'user', 'movie', 'city', 'state'])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/metadata.json', 'r') as fp:\n",
    "    meta = json.load(fp)\n",
    "\n",
    "meta.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Counter([2, 1, 3]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "class Vocab(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, x):\n",
    "        c = Counter(x)\n",
    "        self.lookup_ = {\n",
    "            str(v).lower(): k for k, v in enumerate([x[0] for x in sorted(c.items(), key=lambda x: x[1], reverse=True)])\n",
    "        }\n",
    "\n",
    "    def transform(self, x):\n",
    "        return [self.lookup_.get(str(xx).lower(), len(self.lookup_)+1) for xx in x]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "state_enc = Vocab()\n",
    "state_enc.fit(meta['state'])\n",
    "\n",
    "city_enc = Vocab()\n",
    "city_enc.fit(meta['city'])\n",
    "\n",
    "user_enc = Vocab()\n",
    "user_enc.fit(meta['user'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "        user  movie  hour  day_of_week  month  gender  age  occupation  \\\nindex                                                                    \n956151  6036   3132     1            2      4       1   25          15   \n956152  6037   3132     3            2      4       1   45           1   \n956149  5960   3132    17            5      4       1   45           0   \n956150  6016   3132    20            2      4       0   45           1   \n956146  5643   3132     6            6      5       1   35           1   \n\n                  city state  ...  embed_15  embed_16  embed_17  embed_18  \\\nindex                         ...                                           \n956151     Gainesville    FL  ...  0.511667   1.46494  -2.46967 -1.196152   \n956152       Arlington    TX  ...  0.511667   1.46494  -2.46967 -1.196152   \n956149         Slidell    LA  ...  0.511667   1.46494  -2.46967 -1.196152   \n956150       Nashville    TN  ...  0.511667   1.46494  -2.46967 -1.196152   \n956146  Salt Lake City    UT  ...  0.511667   1.46494  -2.46967 -1.196152   \n\n        embed_19  embed_20  embed_21  embed_22  embed_23  embed_24  \nindex                                                               \n956151   -0.7946  -0.09462   2.84776   2.17518   1.03427  -0.75034  \n956152   -0.7946  -0.09462   2.84776   2.17518   1.03427  -0.75034  \n956149   -0.7946  -0.09462   2.84776   2.17518   1.03427  -0.75034  \n956150   -0.7946  -0.09462   2.84776   2.17518   1.03427  -0.75034  \n956146   -0.7946  -0.09462   2.84776   2.17518   1.03427  -0.75034  \n\n[5 rows x 54 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>movie</th>\n      <th>hour</th>\n      <th>day_of_week</th>\n      <th>month</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>occupation</th>\n      <th>city</th>\n      <th>state</th>\n      <th>...</th>\n      <th>embed_15</th>\n      <th>embed_16</th>\n      <th>embed_17</th>\n      <th>embed_18</th>\n      <th>embed_19</th>\n      <th>embed_20</th>\n      <th>embed_21</th>\n      <th>embed_22</th>\n      <th>embed_23</th>\n      <th>embed_24</th>\n    </tr>\n    <tr>\n      <th>index</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>956151</th>\n      <td>6036</td>\n      <td>3132</td>\n      <td>1</td>\n      <td>2</td>\n      <td>4</td>\n      <td>1</td>\n      <td>25</td>\n      <td>15</td>\n      <td>Gainesville</td>\n      <td>FL</td>\n      <td>...</td>\n      <td>0.511667</td>\n      <td>1.46494</td>\n      <td>-2.46967</td>\n      <td>-1.196152</td>\n      <td>-0.7946</td>\n      <td>-0.09462</td>\n      <td>2.84776</td>\n      <td>2.17518</td>\n      <td>1.03427</td>\n      <td>-0.75034</td>\n    </tr>\n    <tr>\n      <th>956152</th>\n      <td>6037</td>\n      <td>3132</td>\n      <td>3</td>\n      <td>2</td>\n      <td>4</td>\n      <td>1</td>\n      <td>45</td>\n      <td>1</td>\n      <td>Arlington</td>\n      <td>TX</td>\n      <td>...</td>\n      <td>0.511667</td>\n      <td>1.46494</td>\n      <td>-2.46967</td>\n      <td>-1.196152</td>\n      <td>-0.7946</td>\n      <td>-0.09462</td>\n      <td>2.84776</td>\n      <td>2.17518</td>\n      <td>1.03427</td>\n      <td>-0.75034</td>\n    </tr>\n    <tr>\n      <th>956149</th>\n      <td>5960</td>\n      <td>3132</td>\n      <td>17</td>\n      <td>5</td>\n      <td>4</td>\n      <td>1</td>\n      <td>45</td>\n      <td>0</td>\n      <td>Slidell</td>\n      <td>LA</td>\n      <td>...</td>\n      <td>0.511667</td>\n      <td>1.46494</td>\n      <td>-2.46967</td>\n      <td>-1.196152</td>\n      <td>-0.7946</td>\n      <td>-0.09462</td>\n      <td>2.84776</td>\n      <td>2.17518</td>\n      <td>1.03427</td>\n      <td>-0.75034</td>\n    </tr>\n    <tr>\n      <th>956150</th>\n      <td>6016</td>\n      <td>3132</td>\n      <td>20</td>\n      <td>2</td>\n      <td>4</td>\n      <td>0</td>\n      <td>45</td>\n      <td>1</td>\n      <td>Nashville</td>\n      <td>TN</td>\n      <td>...</td>\n      <td>0.511667</td>\n      <td>1.46494</td>\n      <td>-2.46967</td>\n      <td>-1.196152</td>\n      <td>-0.7946</td>\n      <td>-0.09462</td>\n      <td>2.84776</td>\n      <td>2.17518</td>\n      <td>1.03427</td>\n      <td>-0.75034</td>\n    </tr>\n    <tr>\n      <th>956146</th>\n      <td>5643</td>\n      <td>3132</td>\n      <td>6</td>\n      <td>6</td>\n      <td>5</td>\n      <td>1</td>\n      <td>35</td>\n      <td>1</td>\n      <td>Salt Lake City</td>\n      <td>UT</td>\n      <td>...</td>\n      <td>0.511667</td>\n      <td>1.46494</td>\n      <td>-2.46967</td>\n      <td>-1.196152</td>\n      <td>-0.7946</td>\n      <td>-0.09462</td>\n      <td>2.84776</td>\n      <td>2.17518</td>\n      <td>1.03427</td>\n      <td>-0.75034</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 54 columns</p>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('../data/train.parq.gzip').drop('rating', axis=1)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "        rating\nindex         \n956151       5\n956152       4\n956149       5\n956150       3\n956146       4",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rating</th>\n    </tr>\n    <tr>\n      <th>index</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>956151</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>956152</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>956149</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>956150</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>956146</th>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('../data/train.parq.gzip', columns=['rating'])\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "{1, 2, 3, 4, 5}"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df['rating'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, filename, state_vocab, city_vocab, user_vocab):\n",
    "        x = pd.read_parquet(filename).drop('rating', axis=1)\n",
    "        y = pd.read_parquet(filename, columns=['rating'])\n",
    "\n",
    "        x['state'] = state_vocab.transform(x['state'])\n",
    "        x['city'] = city_vocab.transform(x['city'])\n",
    "        x['user'] = user_vocab.transform(x['user'])\n",
    "\n",
    "        self.feature_names = x.columns\n",
    "        self.x = x.to_dict('records')\n",
    "        self.y = torch.tensor(y.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "train = MovieDataset('../data/train.parq.gzip', state_vocab=state_enc, city_vocab=city_enc, user_vocab=user_enc)\n",
    "test = MovieDataset('../data/test.parq.gzip', state_vocab=state_enc, city_vocab=city_enc, user_vocab=user_enc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    },
    {
     "data": {
      "text/plain": "Index(['user', 'movie', 'hour', 'day_of_week', 'month', 'gender', 'age',\n       'occupation', 'city', 'state', 'year', 'genre_action',\n       'genre_adventure', 'genre_animation', 'genre_childrens', 'genre_comedy',\n       'genre_crime', 'genre_documentary', 'genre_drama', 'genre_fantasy',\n       'genre_filmnoir', 'genre_horror', 'genre_musical', 'genre_mystery',\n       'genre_romance', 'genre_scifi', 'genre_thriller', 'genre_war',\n       'genre_western', 'embed_0', 'embed_1', 'embed_2', 'embed_3', 'embed_4',\n       'embed_5', 'embed_6', 'embed_7', 'embed_8', 'embed_9', 'embed_10',\n       'embed_11', 'embed_12', 'embed_13', 'embed_14', 'embed_15', 'embed_16',\n       'embed_17', 'embed_18', 'embed_19', 'embed_20', 'embed_21', 'embed_22',\n       'embed_23', 'embed_24'],\n      dtype='object')"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train.feature_names))\n",
    "train.feature_names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'user': tensor([  66, 1566, 1665,   60]),\n  'movie': tensor([3132, 3132, 3132, 3132]),\n  'hour': tensor([ 1,  3, 17, 20]),\n  'day_of_week': tensor([2, 2, 5, 2]),\n  'month': tensor([4, 4, 4, 4]),\n  'gender': tensor([1, 1, 1, 0]),\n  'age': tensor([25, 45, 45, 45]),\n  'occupation': tensor([15,  1,  0,  1]),\n  'city': tensor([   61,    34, 99999,    38]),\n  'state': tensor([    9,     4, 99999, 99999]),\n  'year': tensor([1919, 1919, 1919, 1919]),\n  'genre_action': tensor([0, 0, 0, 0]),\n  'genre_adventure': tensor([0, 0, 0, 0]),\n  'genre_animation': tensor([0, 0, 0, 0]),\n  'genre_childrens': tensor([0, 0, 0, 0]),\n  'genre_comedy': tensor([1, 1, 1, 1]),\n  'genre_crime': tensor([0, 0, 0, 0]),\n  'genre_documentary': tensor([0, 0, 0, 0]),\n  'genre_drama': tensor([0, 0, 0, 0]),\n  'genre_fantasy': tensor([0, 0, 0, 0]),\n  'genre_filmnoir': tensor([0, 0, 0, 0]),\n  'genre_horror': tensor([0, 0, 0, 0]),\n  'genre_musical': tensor([0, 0, 0, 0]),\n  'genre_mystery': tensor([0, 0, 0, 0]),\n  'genre_romance': tensor([0, 0, 0, 0]),\n  'genre_scifi': tensor([0, 0, 0, 0]),\n  'genre_thriller': tensor([0, 0, 0, 0]),\n  'genre_war': tensor([0, 0, 0, 0]),\n  'genre_western': tensor([0, 0, 0, 0]),\n  'embed_0': tensor([-3.2278, -3.2278, -3.2278, -3.2278], dtype=torch.float64),\n  'embed_1': tensor([-0.0905, -0.0905, -0.0905, -0.0905], dtype=torch.float64),\n  'embed_2': tensor([1.2616, 1.2616, 1.2616, 1.2616], dtype=torch.float64),\n  'embed_3': tensor([0.6548, 0.6548, 0.6548, 0.6548], dtype=torch.float64),\n  'embed_4': tensor([0.5871, 0.5871, 0.5871, 0.5871], dtype=torch.float64),\n  'embed_5': tensor([1.1163, 1.1163, 1.1163, 1.1163], dtype=torch.float64),\n  'embed_6': tensor([3.0645, 3.0645, 3.0645, 3.0645], dtype=torch.float64),\n  'embed_7': tensor([-0.3949, -0.3949, -0.3949, -0.3949], dtype=torch.float64),\n  'embed_8': tensor([-1.4985, -1.4985, -1.4985, -1.4985], dtype=torch.float64),\n  'embed_9': tensor([0.7480, 0.7480, 0.7480, 0.7480], dtype=torch.float64),\n  'embed_10': tensor([-0.8427, -0.8427, -0.8427, -0.8427], dtype=torch.float64),\n  'embed_11': tensor([0.5493, 0.5493, 0.5493, 0.5493], dtype=torch.float64),\n  'embed_12': tensor([-11.3576, -11.3576, -11.3576, -11.3576], dtype=torch.float64),\n  'embed_13': tensor([-0.4556, -0.4556, -0.4556, -0.4556], dtype=torch.float64),\n  'embed_14': tensor([-0.5682, -0.5682, -0.5682, -0.5682], dtype=torch.float64),\n  'embed_15': tensor([0.5117, 0.5117, 0.5117, 0.5117], dtype=torch.float64),\n  'embed_16': tensor([1.4649, 1.4649, 1.4649, 1.4649], dtype=torch.float64),\n  'embed_17': tensor([-2.4697, -2.4697, -2.4697, -2.4697], dtype=torch.float64),\n  'embed_18': tensor([-1.1962, -1.1962, -1.1962, -1.1962], dtype=torch.float64),\n  'embed_19': tensor([-0.7946, -0.7946, -0.7946, -0.7946], dtype=torch.float64),\n  'embed_20': tensor([-0.0946, -0.0946, -0.0946, -0.0946], dtype=torch.float64),\n  'embed_21': tensor([2.8478, 2.8478, 2.8478, 2.8478], dtype=torch.float64),\n  'embed_22': tensor([2.1752, 2.1752, 2.1752, 2.1752], dtype=torch.float64),\n  'embed_23': tensor([1.0343, 1.0343, 1.0343, 1.0343], dtype=torch.float64),\n  'embed_24': tensor([-0.7503, -0.7503, -0.7503, -0.7503], dtype=torch.float64)},\n tensor([[5.],\n         [4.],\n         [5.],\n         [3.]])]"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(train, 4)\n",
    "next(iter(dl))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "z = next(iter(dl))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stack_features(inputs, feat):\n",
    "    return torch.stack([v for k, v in inputs.items() if feat in k], 1)\n",
    "\n",
    "\n",
    "stack_features(z[0], 'genre')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "class RecModel(nn.Module):\n",
    "    def __init__(self, metadata, n_features=54):\n",
    "        super().__init__()\n",
    "        self.meta = metadata\n",
    "        self.embed_dims = {\n",
    "            'large': 25,\n",
    "            'med': 7,\n",
    "            'small': 3\n",
    "        }\n",
    "        self.loss_func = nn.MSELoss()\n",
    "\n",
    "        self.user_embeds = nn.Embedding(\n",
    "            num_embeddings=len(meta['user'].keys()) + 2,\n",
    "            embedding_dim=self.embed_dims['large']\n",
    "        )\n",
    "\n",
    "        self.city_embeds = nn.Embedding(\n",
    "            num_embeddings=len(meta['city'].keys()) + 2,\n",
    "            embedding_dim=self.embed_dims['med']\n",
    "        )\n",
    "\n",
    "        self.state_embeds = nn.Embedding(\n",
    "            num_embeddings=len(meta['state'].keys()) + 2,\n",
    "            embedding_dim=self.embed_dims['small']\n",
    "        )\n",
    "\n",
    "        self.age_embeds = nn.Embedding(\n",
    "            num_embeddings=max(meta['ages']) + 1,\n",
    "            embedding_dim=self.embed_dims['small']\n",
    "        )\n",
    "\n",
    "        self.occ_embeds = nn.Embedding(\n",
    "            num_embeddings=max(meta['occupations']) + 1,\n",
    "            embedding_dim=self.embed_dims['small']\n",
    "        )\n",
    "\n",
    "        self.user_model = nn.Sequential(\n",
    "            nn.LazyLinear(out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.LazyLinear(out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_user = torch.concat(\n",
    "            (\n",
    "                self.user_embeds(x['user']),\n",
    "                self.city_embeds(x['city']),\n",
    "                self.state_embeds(x['state']),\n",
    "                self.age_embeds(x['age']),\n",
    "                self.occ_embeds(x['occupation']),\n",
    "                x['gender'].unsqueeze(-1),\n",
    "                x['hour'].unsqueeze(-1),\n",
    "                x['day_of_week'].unsqueeze(-1),\n",
    "                x['month'].unsqueeze(-1)\n",
    "            ),\n",
    "            dim=1\n",
    "        )\n",
    "        x = self.model(x_user)\n",
    "        return x\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christophersantiago/miniforge3/envs/deeprec/lib/python3.9/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "Epoch:   0%|          | 0/15 [00:00<?, ?it/s]\n",
      "Batch:   0%|          | 0/96 [00:00<?, ?it/s]\u001B[A\n",
      "Batch:   1%|          | 1/96 [00:01<01:50,  1.16s/it]\u001B[A\n",
      "Batch:   2%|▏         | 2/96 [00:01<01:03,  1.47it/s]\u001B[A\n",
      "Batch:   3%|▎         | 3/96 [00:01<00:48,  1.91it/s]\u001B[A\n",
      "Batch:   4%|▍         | 4/96 [00:02<00:41,  2.24it/s]\u001B[A\n",
      "Batch:   5%|▌         | 5/96 [00:02<00:44,  2.05it/s]\u001B[A\n",
      "Batch:   6%|▋         | 6/96 [00:03<00:38,  2.31it/s]\u001B[A\n",
      "Batch:   7%|▋         | 7/96 [00:03<00:36,  2.42it/s]\u001B[A\n",
      "Batch:   8%|▊         | 8/96 [00:03<00:35,  2.48it/s]\u001B[A\n",
      "Batch:   9%|▉         | 9/96 [00:04<00:34,  2.55it/s]\u001B[A\n",
      "Batch:  10%|█         | 10/96 [00:04<00:33,  2.56it/s]\u001B[A\n",
      "Batch:  11%|█▏        | 11/96 [00:05<00:38,  2.23it/s]\u001B[A\n",
      "Batch:  12%|█▎        | 12/96 [00:05<00:36,  2.31it/s]\u001B[A\n",
      "Batch:  14%|█▎        | 13/96 [00:06<00:53,  1.56it/s]\u001B[A\n",
      "Batch:  15%|█▍        | 14/96 [00:07<00:47,  1.72it/s]\u001B[A\n",
      "Batch:  16%|█▌        | 15/96 [00:07<00:44,  1.83it/s]\u001B[A\n",
      "Batch:  17%|█▋        | 16/96 [00:07<00:39,  2.04it/s]\u001B[A\n",
      "Batch:  18%|█▊        | 17/96 [00:08<00:39,  1.99it/s]\u001B[A\n",
      "Batch:  19%|█▉        | 18/96 [00:08<00:35,  2.21it/s]\u001B[A\n",
      "Batch:  20%|█▉        | 19/96 [00:09<00:31,  2.42it/s]\u001B[A\n",
      "Batch:  21%|██        | 20/96 [00:09<00:29,  2.56it/s]\u001B[A\n",
      "Batch:  22%|██▏       | 21/96 [00:09<00:28,  2.66it/s]\u001B[A\n",
      "Batch:  23%|██▎       | 22/96 [00:10<00:27,  2.70it/s]\u001B[A\n",
      "Batch:  24%|██▍       | 23/96 [00:10<00:31,  2.32it/s]\u001B[A\n",
      "Batch:  25%|██▌       | 24/96 [00:11<00:30,  2.37it/s]\u001B[A\n",
      "Batch:  26%|██▌       | 25/96 [00:11<00:28,  2.45it/s]\u001B[A\n",
      "Batch:  27%|██▋       | 26/96 [00:11<00:27,  2.51it/s]\u001B[A\n",
      "Batch:  28%|██▊       | 27/96 [00:12<00:26,  2.57it/s]\u001B[A\n",
      "Batch:  29%|██▉       | 28/96 [00:12<00:25,  2.65it/s]\u001B[A\n",
      "Batch:  30%|███       | 29/96 [00:13<00:28,  2.35it/s]\u001B[A\n",
      "Batch:  31%|███▏      | 30/96 [00:13<00:25,  2.55it/s]\u001B[A\n",
      "Batch:  32%|███▏      | 31/96 [00:13<00:24,  2.70it/s]\u001B[A\n",
      "Batch:  33%|███▎      | 32/96 [00:14<00:22,  2.83it/s]\u001B[A\n",
      "Batch:  34%|███▍      | 33/96 [00:14<00:21,  2.89it/s]\u001B[A\n",
      "Batch:  35%|███▌      | 34/96 [00:14<00:21,  2.92it/s]\u001B[A\n",
      "Batch:  36%|███▋      | 35/96 [00:15<00:23,  2.57it/s]\u001B[A\n",
      "Batch:  38%|███▊      | 36/96 [00:15<00:21,  2.74it/s]\u001B[A\n",
      "Batch:  39%|███▊      | 37/96 [00:15<00:20,  2.86it/s]\u001B[A\n",
      "Batch:  40%|███▉      | 38/96 [00:16<00:19,  2.95it/s]\u001B[A\n",
      "Batch:  41%|████      | 39/96 [00:16<00:18,  3.00it/s]\u001B[A\n",
      "Batch:  42%|████▏     | 40/96 [00:16<00:18,  3.04it/s]\u001B[A\n",
      "Batch:  43%|████▎     | 41/96 [00:17<00:17,  3.09it/s]\u001B[A\n",
      "Batch:  44%|████▍     | 42/96 [00:17<00:20,  2.68it/s]\u001B[A\n",
      "Batch:  45%|████▍     | 43/96 [00:17<00:18,  2.81it/s]\u001B[A\n",
      "Batch:  46%|████▌     | 44/96 [00:18<00:18,  2.77it/s]\u001B[A\n",
      "Batch:  47%|████▋     | 45/96 [00:18<00:18,  2.74it/s]\u001B[A\n",
      "Batch:  48%|████▊     | 46/96 [00:19<00:18,  2.75it/s]\u001B[A\n",
      "Batch:  49%|████▉     | 47/96 [00:19<00:21,  2.30it/s]\u001B[A\n",
      "Batch:  50%|█████     | 48/96 [00:20<00:20,  2.39it/s]\u001B[A\n",
      "Batch:  51%|█████     | 49/96 [00:20<00:19,  2.45it/s]\u001B[A\n",
      "Batch:  52%|█████▏    | 50/96 [00:20<00:18,  2.54it/s]\u001B[A\n",
      "Batch:  53%|█████▎    | 51/96 [00:21<00:17,  2.63it/s]\u001B[A\n",
      "Batch:  54%|█████▍    | 52/96 [00:21<00:16,  2.66it/s]\u001B[A\n",
      "Batch:  55%|█████▌    | 53/96 [00:21<00:15,  2.80it/s]\u001B[A\n",
      "Batch:  56%|█████▋    | 54/96 [00:22<00:16,  2.48it/s]\u001B[A\n",
      "Batch:  57%|█████▋    | 55/96 [00:22<00:15,  2.68it/s]\u001B[A\n",
      "Batch:  58%|█████▊    | 56/96 [00:22<00:14,  2.82it/s]\u001B[A\n",
      "Batch:  59%|█████▉    | 57/96 [00:23<00:13,  2.84it/s]\u001B[A\n",
      "Batch:  60%|██████    | 58/96 [00:23<00:13,  2.85it/s]\u001B[A\n",
      "Batch:  61%|██████▏   | 59/96 [00:23<00:12,  2.86it/s]\u001B[A\n",
      "Batch:  62%|██████▎   | 60/96 [00:24<00:14,  2.43it/s]\u001B[A\n",
      "Batch:  64%|██████▎   | 61/96 [00:24<00:14,  2.49it/s]\u001B[A\n",
      "Batch:  65%|██████▍   | 62/96 [00:25<00:13,  2.56it/s]\u001B[A\n",
      "Batch:  66%|██████▌   | 63/96 [00:25<00:12,  2.57it/s]\u001B[A\n",
      "Batch:  67%|██████▋   | 64/96 [00:26<00:12,  2.50it/s]\u001B[A\n",
      "Batch:  68%|██████▊   | 65/96 [00:26<00:12,  2.49it/s]\u001B[A\n",
      "Batch:  69%|██████▉   | 66/96 [00:27<00:14,  2.11it/s]\u001B[A\n",
      "Batch:  70%|██████▉   | 67/96 [00:27<00:13,  2.23it/s]\u001B[A\n",
      "Batch:  71%|███████   | 68/96 [00:27<00:11,  2.37it/s]\u001B[A\n",
      "Batch:  72%|███████▏  | 69/96 [00:28<00:10,  2.56it/s]\u001B[A\n",
      "Batch:  73%|███████▎  | 70/96 [00:28<00:09,  2.69it/s]\u001B[A\n",
      "Batch:  74%|███████▍  | 71/96 [00:28<00:08,  2.80it/s]\u001B[A\n",
      "Batch:  75%|███████▌  | 72/96 [00:29<00:09,  2.46it/s]\u001B[A\n",
      "Batch:  76%|███████▌  | 73/96 [00:29<00:08,  2.59it/s]\u001B[A\n",
      "Batch:  77%|███████▋  | 74/96 [00:30<00:08,  2.66it/s]\u001B[A\n",
      "Batch:  78%|███████▊  | 75/96 [00:30<00:07,  2.73it/s]\u001B[A\n",
      "Batch:  79%|███████▉  | 76/96 [00:30<00:07,  2.83it/s]\u001B[A\n",
      "Batch:  80%|████████  | 77/96 [00:31<00:06,  2.85it/s]\u001B[A\n",
      "Batch:  81%|████████▏ | 78/96 [00:31<00:07,  2.48it/s]\u001B[A\n",
      "Batch:  82%|████████▏ | 79/96 [00:31<00:06,  2.55it/s]\u001B[A\n",
      "Batch:  83%|████████▎ | 80/96 [00:32<00:06,  2.59it/s]\u001B[A\n",
      "Batch:  84%|████████▍ | 81/96 [00:32<00:05,  2.61it/s]\u001B[A\n",
      "Batch:  85%|████████▌ | 82/96 [00:33<00:05,  2.63it/s]\u001B[A\n",
      "Batch:  86%|████████▋ | 83/96 [00:33<00:04,  2.64it/s]\u001B[A\n",
      "Batch:  88%|████████▊ | 84/96 [00:34<00:05,  2.30it/s]\u001B[A\n",
      "Batch:  89%|████████▊ | 85/96 [00:34<00:04,  2.35it/s]\u001B[A\n",
      "Batch:  90%|████████▉ | 86/96 [00:34<00:04,  2.41it/s]\u001B[A\n",
      "Batch:  91%|█████████ | 87/96 [00:35<00:03,  2.46it/s]\u001B[A\n",
      "Batch:  92%|█████████▏| 88/96 [00:35<00:03,  2.57it/s]\u001B[A\n",
      "Batch:  93%|█████████▎| 89/96 [00:36<00:03,  1.83it/s]\u001B[A\n",
      "Batch:  94%|█████████▍| 90/96 [00:36<00:03,  1.88it/s]\u001B[A\n",
      "Batch:  95%|█████████▍| 91/96 [00:37<00:02,  2.14it/s]\u001B[A\n",
      "Batch:  96%|█████████▌| 92/96 [00:37<00:01,  2.37it/s]\u001B[A\n",
      "Batch:  97%|█████████▋| 93/96 [00:37<00:01,  2.58it/s]\u001B[A\n",
      "Batch:  98%|█████████▊| 94/96 [00:38<00:00,  2.72it/s]\u001B[A\n",
      "Batch:  99%|█████████▉| 95/96 [00:38<00:00,  2.85it/s]\u001B[A\n",
      "Batch: 100%|██████████| 96/96 [00:39<00:00,  2.46it/s]\u001B[A\n",
      "                                                      \u001B[A\n",
      "Batch:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Batch:  20%|██        | 1/5 [00:00<00:00,  5.61it/s]\u001B[A\n",
      "Batch:  40%|████      | 2/5 [00:00<00:00,  5.61it/s]\u001B[A\n",
      "Batch:  60%|██████    | 3/5 [00:00<00:00,  5.66it/s]\u001B[A\n",
      "Batch:  80%|████████  | 4/5 [00:00<00:00,  5.62it/s]\u001B[A\n",
      "Epoch:   7%|▋         | 1/15 [00:39<09:17, 39.82s/it][A\n",
      "Batch:   0%|          | 0/96 [00:00<?, ?it/s]\u001B[A\n",
      "Batch:   1%|          | 1/96 [00:00<00:41,  2.30it/s]\u001B[A\n",
      "Batch:   2%|▏         | 2/96 [00:00<00:42,  2.20it/s]\u001B[A\n",
      "Batch:   3%|▎         | 3/96 [00:01<00:51,  1.81it/s]\u001B[A\n",
      "Batch:   4%|▍         | 4/96 [00:02<00:46,  1.96it/s]\u001B[A\n",
      "Batch:   5%|▌         | 5/96 [00:02<00:44,  2.03it/s]\u001B[A\n",
      "Batch:   6%|▋         | 6/96 [00:02<00:41,  2.17it/s]\u001B[A\n",
      "Batch:   7%|▋         | 7/96 [00:03<00:38,  2.29it/s]\u001B[A\n",
      "Batch:   8%|▊         | 8/96 [00:03<00:41,  2.14it/s]\u001B[A\n",
      "Batch:   9%|▉         | 9/96 [00:04<00:36,  2.35it/s]\u001B[A\n",
      "Batch:  10%|█         | 10/96 [00:04<00:34,  2.51it/s]\u001B[A\n",
      "Batch:  11%|█▏        | 11/96 [00:04<00:31,  2.67it/s]\u001B[A\n",
      "Batch:  12%|█▎        | 12/96 [00:05<00:30,  2.80it/s]\u001B[A\n",
      "Batch:  14%|█▎        | 13/96 [00:05<00:29,  2.81it/s]\u001B[A\n",
      "Batch:  15%|█▍        | 14/96 [00:06<00:43,  1.90it/s]\u001B[A\n",
      "Batch:  16%|█▌        | 15/96 [00:06<00:43,  1.87it/s]\u001B[A\n",
      "Batch:  17%|█▋        | 16/96 [00:07<00:37,  2.14it/s]\u001B[A\n",
      "Batch:  18%|█▊        | 17/96 [00:07<00:33,  2.39it/s]\u001B[A\n",
      "Batch:  19%|█▉        | 18/96 [00:07<00:30,  2.59it/s]\u001B[A\n",
      "Batch:  20%|█▉        | 19/96 [00:08<00:28,  2.66it/s]\u001B[A\n",
      "Batch:  21%|██        | 20/96 [00:08<00:28,  2.63it/s]\u001B[A\n",
      "Batch:  22%|██▏       | 21/96 [00:09<00:32,  2.29it/s]\u001B[A\n",
      "Batch:  23%|██▎       | 22/96 [00:09<00:30,  2.40it/s]\u001B[A\n",
      "Batch:  24%|██▍       | 23/96 [00:09<00:31,  2.34it/s]\u001B[A\n",
      "Batch:  25%|██▌       | 24/96 [00:10<00:29,  2.44it/s]\u001B[A\n",
      "Batch:  26%|██▌       | 25/96 [00:10<00:28,  2.47it/s]\u001B[A\n",
      "Batch:  27%|██▋       | 26/96 [00:11<00:27,  2.53it/s]\u001B[A\n",
      "Batch:  28%|██▊       | 27/96 [00:11<00:30,  2.25it/s]\u001B[A\n",
      "Batch:  29%|██▉       | 28/96 [00:12<00:28,  2.39it/s]\u001B[A\n",
      "Batch:  30%|███       | 29/96 [00:12<00:26,  2.53it/s]\u001B[A\n",
      "Batch:  31%|███▏      | 30/96 [00:12<00:24,  2.68it/s]\u001B[A\n",
      "Batch:  32%|███▏      | 31/96 [00:13<00:23,  2.79it/s]\u001B[A\n",
      "Batch:  33%|███▎      | 32/96 [00:13<00:21,  2.91it/s]\u001B[A\n",
      "Batch:  34%|███▍      | 33/96 [00:13<00:24,  2.54it/s]\u001B[A\n",
      "Batch:  35%|███▌      | 34/96 [00:14<00:22,  2.71it/s]\u001B[A\n",
      "Batch:  36%|███▋      | 35/96 [00:14<00:21,  2.82it/s]\u001B[A\n",
      "Batch:  38%|███▊      | 36/96 [00:14<00:20,  2.92it/s]\u001B[A\n",
      "Batch:  39%|███▊      | 37/96 [00:15<00:19,  2.96it/s]\u001B[A\n",
      "Batch:  40%|███▉      | 38/96 [00:15<00:19,  2.98it/s]\u001B[A\n",
      "Batch:  41%|████      | 39/96 [00:16<00:22,  2.50it/s]\u001B[A\n",
      "Batch:  42%|████▏     | 40/96 [00:16<00:21,  2.56it/s]\u001B[A\n",
      "Batch:  43%|████▎     | 41/96 [00:16<00:25,  2.17it/s]\u001B[A\n",
      "Batch:  44%|████▍     | 42/96 [00:17<00:33,  1.60it/s]\u001B[A\n",
      "Batch:  45%|████▍     | 43/96 [00:18<00:29,  1.78it/s]\u001B[A\n",
      "Batch:  46%|████▌     | 44/96 [00:18<00:26,  1.98it/s]\u001B[A\n",
      "Batch:  47%|████▋     | 45/96 [00:19<00:22,  2.22it/s]\u001B[A\n",
      "Batch:  48%|████▊     | 46/96 [00:19<00:23,  2.15it/s]\u001B[A\n",
      "Batch:  49%|████▉     | 47/96 [00:19<00:20,  2.38it/s]\u001B[A\n",
      "Batch:  50%|█████     | 48/96 [00:20<00:18,  2.58it/s]\u001B[A\n",
      "Batch:  51%|█████     | 49/96 [00:20<00:17,  2.70it/s]\u001B[A\n",
      "Batch:  52%|█████▏    | 50/96 [00:20<00:16,  2.83it/s]\u001B[A\n",
      "Batch:  53%|█████▎    | 51/96 [00:21<00:15,  2.89it/s]\u001B[A\n",
      "Batch:  54%|█████▍    | 52/96 [00:21<00:17,  2.49it/s]\u001B[A\n",
      "Batch:  55%|█████▌    | 53/96 [00:22<00:21,  2.02it/s]\u001B[A\n",
      "Batch:  56%|█████▋    | 54/96 [00:22<00:19,  2.20it/s]\u001B[A\n",
      "Batch:  57%|█████▋    | 55/96 [00:23<00:25,  1.60it/s]\u001B[A\n",
      "Batch:  58%|█████▊    | 56/96 [00:24<00:22,  1.76it/s]\u001B[A\n",
      "Batch:  59%|█████▉    | 57/96 [00:24<00:20,  1.91it/s]\u001B[A\n",
      "Batch:  60%|██████    | 58/96 [00:25<00:21,  1.79it/s]\u001B[A\n",
      "Batch:  61%|██████▏   | 59/96 [00:26<00:26,  1.40it/s]\u001B[A\n",
      "Batch:  62%|██████▎   | 60/96 [00:26<00:22,  1.59it/s]\u001B[A\n",
      "Batch:  64%|██████▎   | 61/96 [00:27<00:19,  1.81it/s]\u001B[A\n",
      "Batch:  65%|██████▍   | 62/96 [00:27<00:16,  2.05it/s]\u001B[A\n",
      "Batch:  66%|██████▌   | 63/96 [00:27<00:14,  2.26it/s]\u001B[A\n",
      "Batch:  67%|██████▋   | 64/96 [00:28<00:15,  2.08it/s]\u001B[A\n",
      "Batch:  68%|██████▊   | 65/96 [00:28<00:13,  2.28it/s]\u001B[A\n",
      "Batch:  69%|██████▉   | 66/96 [00:29<00:12,  2.47it/s]\u001B[A\n",
      "Batch:  70%|██████▉   | 67/96 [00:29<00:11,  2.55it/s]\u001B[A\n",
      "Batch:  71%|███████   | 68/96 [00:29<00:10,  2.63it/s]\u001B[A\n",
      "Batch:  72%|███████▏  | 69/96 [00:30<00:09,  2.77it/s]\u001B[A\n",
      "Batch:  73%|███████▎  | 70/96 [00:30<00:10,  2.45it/s]\u001B[A\n",
      "Batch:  74%|███████▍  | 71/96 [00:30<00:09,  2.64it/s]\u001B[A\n",
      "Batch:  75%|███████▌  | 72/96 [00:31<00:08,  2.81it/s]\u001B[A\n",
      "Batch:  76%|███████▌  | 73/96 [00:31<00:07,  2.93it/s]\u001B[A\n",
      "Batch:  77%|███████▋  | 74/96 [00:31<00:07,  2.99it/s]\u001B[A\n",
      "Batch:  78%|███████▊  | 75/96 [00:32<00:07,  2.94it/s]\u001B[A\n",
      "Batch:  79%|███████▉  | 76/96 [00:32<00:08,  2.38it/s]\u001B[A\n",
      "Batch:  80%|████████  | 77/96 [00:33<00:08,  2.33it/s]\u001B[A\n",
      "Batch:  81%|████████▏ | 78/96 [00:33<00:08,  2.19it/s]\u001B[A"
     ]
    }
   ],
   "source": [
    "NOW = datetime.now().strftime('%Y%m%d-%H%M')\n",
    "LOG_DIR = ROOT.joinpath('runs', NOW)\n",
    "BATCH = 10_000\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=BATCH, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=BATCH)\n",
    "\n",
    "device = set_device()\n",
    "mod = RecModel(metadata=meta)\n",
    "opt = torch.optim.AdamW(mod.parameters(), lr=0.01)\n",
    "trainer = Trainer(\n",
    "    mod, epochs=15, device=device, log_dir=LOG_DIR, checkpoint_file=LOG_DIR.joinpath('model.pt'),\n",
    "    optimizer=opt, score_funcs={'mse': torchmetrics.MeanSquaredError()}\n",
    ")\n",
    "trainer.fit(train_loader, test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "{e:v for e,v in enumerate(torch.sqrt(torch.tensor(trainer.results['valid_mse'])))}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<hr>\n",
    "\n",
    "# DEBUGGING"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'user': tensor([  66, 1566, 1665,   60,   30, 2355, 1692,   64,  934, 1067, 1065, 2515,\n           566, 1637,  862,  129,  219, 1960,   17,   28,  441,  327,   53,  431,\n            27,  812, 2028,  803,  137, 2515, 1158,  682]),\n  'movie': tensor([3132, 3132, 3132, 3132, 3132, 2821, 3132, 3132, 3132, 3132, 3132, 3132,\n          3132, 3132, 3132, 3132, 3132, 3132, 3132, 2823, 3132, 3132, 3132, 3132,\n          3132, 3132, 3132, 3132, 3132, 3132, 3132, 2823]),\n  'hour': tensor([ 1,  3, 17, 20,  6, 21,  6,  7, 23, 23, 12, 21, 21, 21,  0,  0,  2, 14,\n          15, 18,  4, 13, 16, 16, 17,  8, 21,  2,  3,  4,  6,  8]),\n  'day_of_week': tensor([2, 2, 5, 2, 6, 2, 0, 5, 3, 3, 2, 5, 4, 5, 4, 5, 0, 3, 3, 0, 6, 3, 0, 1,\n          5, 1, 2, 4, 1, 0, 2, 2]),\n  'month': tensor([ 4,  4,  4,  4,  5,  5,  6,  6,  6,  6,  7,  7,  7,  7,  8,  8,  8,  8,\n           8,  8,  9,  9,  9,  9,  9, 10, 10, 11, 11, 11, 11, 11]),\n  'gender': tensor([1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n          1, 1, 0, 1, 1, 1, 1, 1]),\n  'age': tensor([25, 45, 45, 45, 35, 35, 50, 25, 56, 35, 35, 25, 35, 45, 25, 56, 45, 45,\n          25, 25, 35, 45, 50, 25, 25, 35, 45, 56, 45, 50, 50, 45]),\n  'occupation': tensor([15,  1,  0,  1,  1, 14,  1,  7, 20,  0,  4, 14,  6,  1,  3, 14,  1,  3,\n          19,  4, 20, 20,  6, 20, 14, 20, 11,  7,  6, 14, 20,  2]),\n  'city': tensor([ 61,  34, 466,  38,  59, 466, 127,   6, 242,  35, 466,   2,  15, 466,\n            7,  94,  14, 416, 175,  13, 136, 195,  51, 135, 187,   5,   2, 466,\n           65,  27,  17, 260]),\n  'state': tensor([ 9,  4, 20, 20, 20, 20,  8,  0,  0, 13,  6,  0,  7, 10,  0,  0,  6,  7,\n           1,  4,  0, 20,  4,  0,  0,  8,  0,  5,  5, 20,  1, 20]),\n  'year': tensor([1919, 1919, 1919, 1919, 1919, 1919, 1919, 1919, 1919, 1919, 1919, 1919,\n          1919, 1919, 1919, 1919, 1919, 1919, 1919, 1919, 1919, 1919, 1919, 1919,\n          1919, 1919, 1919, 1919, 1919, 1919, 1919, 1919]),\n  'genre_action': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 1]),\n  'genre_adventure': tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_animation': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_childrens': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_comedy': tensor([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n          1, 1, 1, 1, 1, 1, 1, 0]),\n  'genre_crime': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_documentary': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_drama': tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 1]),\n  'genre_fantasy': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_filmnoir': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_horror': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_musical': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_mystery': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_romance': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_scifi': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_thriller': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_war': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_western': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'embed_0': tensor([-3.2278, -3.2278, -3.2278, -3.2278, -3.2278, -1.4783, -3.2278, -3.2278,\n          -3.2278, -3.2278, -3.2278, -3.2278, -3.2278, -3.2278, -3.2278, -3.2278,\n          -3.2278, -3.2278, -3.2278,  5.3274, -3.2278, -3.2278, -3.2278, -3.2278,\n          -3.2278, -3.2278, -3.2278, -3.2278, -3.2278, -3.2278, -3.2278,  5.3274],\n         dtype=torch.float64),\n  'embed_1': tensor([-0.0905, -0.0905, -0.0905, -0.0905, -0.0905, -0.0899, -0.0905, -0.0905,\n          -0.0905, -0.0905, -0.0905, -0.0905, -0.0905, -0.0905, -0.0905, -0.0905,\n          -0.0905, -0.0905, -0.0905, -1.1371, -0.0905, -0.0905, -0.0905, -0.0905,\n          -0.0905, -0.0905, -0.0905, -0.0905, -0.0905, -0.0905, -0.0905, -1.1371],\n         dtype=torch.float64),\n  'embed_2': tensor([ 1.2616,  1.2616,  1.2616,  1.2616,  1.2616, -0.3488,  1.2616,  1.2616,\n           1.2616,  1.2616,  1.2616,  1.2616,  1.2616,  1.2616,  1.2616,  1.2616,\n           1.2616,  1.2616,  1.2616,  0.0224,  1.2616,  1.2616,  1.2616,  1.2616,\n           1.2616,  1.2616,  1.2616,  1.2616,  1.2616,  1.2616,  1.2616,  0.0224],\n         dtype=torch.float64),\n  'embed_3': tensor([ 0.6548,  0.6548,  0.6548,  0.6548,  0.6548, -0.7970,  0.6548,  0.6548,\n           0.6548,  0.6548,  0.6548,  0.6548,  0.6548,  0.6548,  0.6548,  0.6548,\n           0.6548,  0.6548,  0.6548, -1.4486,  0.6548,  0.6548,  0.6548,  0.6548,\n           0.6548,  0.6548,  0.6548,  0.6548,  0.6548,  0.6548,  0.6548, -1.4486],\n         dtype=torch.float64),\n  'embed_4': tensor([ 0.5871,  0.5871,  0.5871,  0.5871,  0.5871,  2.0920,  0.5871,  0.5871,\n           0.5871,  0.5871,  0.5871,  0.5871,  0.5871,  0.5871,  0.5871,  0.5871,\n           0.5871,  0.5871,  0.5871, -2.0371,  0.5871,  0.5871,  0.5871,  0.5871,\n           0.5871,  0.5871,  0.5871,  0.5871,  0.5871,  0.5871,  0.5871, -2.0371],\n         dtype=torch.float64),\n  'embed_5': tensor([ 1.1163,  1.1163,  1.1163,  1.1163,  1.1163, -1.2675,  1.1163,  1.1163,\n           1.1163,  1.1163,  1.1163,  1.1163,  1.1163,  1.1163,  1.1163,  1.1163,\n           1.1163,  1.1163,  1.1163,  3.3954,  1.1163,  1.1163,  1.1163,  1.1163,\n           1.1163,  1.1163,  1.1163,  1.1163,  1.1163,  1.1163,  1.1163,  3.3954],\n         dtype=torch.float64),\n  'embed_6': tensor([ 3.0645,  3.0645,  3.0645,  3.0645,  3.0645,  3.7290,  3.0645,  3.0645,\n           3.0645,  3.0645,  3.0645,  3.0645,  3.0645,  3.0645,  3.0645,  3.0645,\n           3.0645,  3.0645,  3.0645, -1.7011,  3.0645,  3.0645,  3.0645,  3.0645,\n           3.0645,  3.0645,  3.0645,  3.0645,  3.0645,  3.0645,  3.0645, -1.7011],\n         dtype=torch.float64),\n  'embed_7': tensor([-0.3949, -0.3949, -0.3949, -0.3949, -0.3949, -0.3805, -0.3949, -0.3949,\n          -0.3949, -0.3949, -0.3949, -0.3949, -0.3949, -0.3949, -0.3949, -0.3949,\n          -0.3949, -0.3949, -0.3949, -4.7617, -0.3949, -0.3949, -0.3949, -0.3949,\n          -0.3949, -0.3949, -0.3949, -0.3949, -0.3949, -0.3949, -0.3949, -4.7617],\n         dtype=torch.float64),\n  'embed_8': tensor([-1.4985, -1.4985, -1.4985, -1.4985, -1.4985,  0.2837, -1.4985, -1.4985,\n          -1.4985, -1.4985, -1.4985, -1.4985, -1.4985, -1.4985, -1.4985, -1.4985,\n          -1.4985, -1.4985, -1.4985,  0.2152, -1.4985, -1.4985, -1.4985, -1.4985,\n          -1.4985, -1.4985, -1.4985, -1.4985, -1.4985, -1.4985, -1.4985,  0.2152],\n         dtype=torch.float64),\n  'embed_9': tensor([ 0.7480,  0.7480,  0.7480,  0.7480,  0.7480,  0.2406,  0.7480,  0.7480,\n           0.7480,  0.7480,  0.7480,  0.7480,  0.7480,  0.7480,  0.7480,  0.7480,\n           0.7480,  0.7480,  0.7480, -1.0419,  0.7480,  0.7480,  0.7480,  0.7480,\n           0.7480,  0.7480,  0.7480,  0.7480,  0.7480,  0.7480,  0.7480, -1.0419],\n         dtype=torch.float64),\n  'embed_10': tensor([-0.8427, -0.8427, -0.8427, -0.8427, -0.8427,  0.0801, -0.8427, -0.8427,\n          -0.8427, -0.8427, -0.8427, -0.8427, -0.8427, -0.8427, -0.8427, -0.8427,\n          -0.8427, -0.8427, -0.8427, -0.6382, -0.8427, -0.8427, -0.8427, -0.8427,\n          -0.8427, -0.8427, -0.8427, -0.8427, -0.8427, -0.8427, -0.8427, -0.6382],\n         dtype=torch.float64),\n  'embed_11': tensor([ 0.5493,  0.5493,  0.5493,  0.5493,  0.5493, -0.9175,  0.5493,  0.5493,\n           0.5493,  0.5493,  0.5493,  0.5493,  0.5493,  0.5493,  0.5493,  0.5493,\n           0.5493,  0.5493,  0.5493,  5.7177,  0.5493,  0.5493,  0.5493,  0.5493,\n           0.5493,  0.5493,  0.5493,  0.5493,  0.5493,  0.5493,  0.5493,  5.7177],\n         dtype=torch.float64),\n  'embed_12': tensor([-11.3576, -11.3576, -11.3576, -11.3576, -11.3576, -12.9007, -11.3576,\n          -11.3576, -11.3576, -11.3576, -11.3576, -11.3576, -11.3576, -11.3576,\n          -11.3576, -11.3576, -11.3576, -11.3576, -11.3576, -18.5922, -11.3576,\n          -11.3576, -11.3576, -11.3576, -11.3576, -11.3576, -11.3576, -11.3576,\n          -11.3576, -11.3576, -11.3576, -18.5922], dtype=torch.float64),\n  'embed_13': tensor([-0.4556, -0.4556, -0.4556, -0.4556, -0.4556,  0.1208, -0.4556, -0.4556,\n          -0.4556, -0.4556, -0.4556, -0.4556, -0.4556, -0.4556, -0.4556, -0.4556,\n          -0.4556, -0.4556, -0.4556, -3.5370, -0.4556, -0.4556, -0.4556, -0.4556,\n          -0.4556, -0.4556, -0.4556, -0.4556, -0.4556, -0.4556, -0.4556, -3.5370],\n         dtype=torch.float64),\n  'embed_14': tensor([-0.5682, -0.5682, -0.5682, -0.5682, -0.5682, -1.9190, -0.5682, -0.5682,\n          -0.5682, -0.5682, -0.5682, -0.5682, -0.5682, -0.5682, -0.5682, -0.5682,\n          -0.5682, -0.5682, -0.5682,  0.1743, -0.5682, -0.5682, -0.5682, -0.5682,\n          -0.5682, -0.5682, -0.5682, -0.5682, -0.5682, -0.5682, -0.5682,  0.1743],\n         dtype=torch.float64),\n  'embed_15': tensor([0.5117, 0.5117, 0.5117, 0.5117, 0.5117, 1.6354, 0.5117, 0.5117, 0.5117,\n          0.5117, 0.5117, 0.5117, 0.5117, 0.5117, 0.5117, 0.5117, 0.5117, 0.5117,\n          0.5117, 1.5627, 0.5117, 0.5117, 0.5117, 0.5117, 0.5117, 0.5117, 0.5117,\n          0.5117, 0.5117, 0.5117, 0.5117, 1.5627], dtype=torch.float64),\n  'embed_16': tensor([1.4649, 1.4649, 1.4649, 1.4649, 1.4649, 0.3634, 1.4649, 1.4649, 1.4649,\n          1.4649, 1.4649, 1.4649, 1.4649, 1.4649, 1.4649, 1.4649, 1.4649, 1.4649,\n          1.4649, 4.9485, 1.4649, 1.4649, 1.4649, 1.4649, 1.4649, 1.4649, 1.4649,\n          1.4649, 1.4649, 1.4649, 1.4649, 4.9485], dtype=torch.float64),\n  'embed_17': tensor([-2.4697, -2.4697, -2.4697, -2.4697, -2.4697, -1.5919, -2.4697, -2.4697,\n          -2.4697, -2.4697, -2.4697, -2.4697, -2.4697, -2.4697, -2.4697, -2.4697,\n          -2.4697, -2.4697, -2.4697,  2.8856, -2.4697, -2.4697, -2.4697, -2.4697,\n          -2.4697, -2.4697, -2.4697, -2.4697, -2.4697, -2.4697, -2.4697,  2.8856],\n         dtype=torch.float64),\n  'embed_18': tensor([-1.1962, -1.1962, -1.1962, -1.1962, -1.1962,  0.7238, -1.1962, -1.1962,\n          -1.1962, -1.1962, -1.1962, -1.1962, -1.1962, -1.1962, -1.1962, -1.1962,\n          -1.1962, -1.1962, -1.1962, -5.2075, -1.1962, -1.1962, -1.1962, -1.1962,\n          -1.1962, -1.1962, -1.1962, -1.1962, -1.1962, -1.1962, -1.1962, -5.2075],\n         dtype=torch.float64),\n  'embed_19': tensor([-7.9460e-01, -7.9460e-01, -7.9460e-01, -7.9460e-01, -7.9460e-01,\n           2.7999e-04, -7.9460e-01, -7.9460e-01, -7.9460e-01, -7.9460e-01,\n          -7.9460e-01, -7.9460e-01, -7.9460e-01, -7.9460e-01, -7.9460e-01,\n          -7.9460e-01, -7.9460e-01, -7.9460e-01, -7.9460e-01, -2.8623e+00,\n          -7.9460e-01, -7.9460e-01, -7.9460e-01, -7.9460e-01, -7.9460e-01,\n          -7.9460e-01, -7.9460e-01, -7.9460e-01, -7.9460e-01, -7.9460e-01,\n          -7.9460e-01, -2.8623e+00], dtype=torch.float64),\n  'embed_20': tensor([-0.0946, -0.0946, -0.0946, -0.0946, -0.0946,  0.6792, -0.0946, -0.0946,\n          -0.0946, -0.0946, -0.0946, -0.0946, -0.0946, -0.0946, -0.0946, -0.0946,\n          -0.0946, -0.0946, -0.0946, -1.1122, -0.0946, -0.0946, -0.0946, -0.0946,\n          -0.0946, -0.0946, -0.0946, -0.0946, -0.0946, -0.0946, -0.0946, -1.1122],\n         dtype=torch.float64),\n  'embed_21': tensor([2.8478, 2.8478, 2.8478, 2.8478, 2.8478, 2.4738, 2.8478, 2.8478, 2.8478,\n          2.8478, 2.8478, 2.8478, 2.8478, 2.8478, 2.8478, 2.8478, 2.8478, 2.8478,\n          2.8478, 4.7896, 2.8478, 2.8478, 2.8478, 2.8478, 2.8478, 2.8478, 2.8478,\n          2.8478, 2.8478, 2.8478, 2.8478, 4.7896], dtype=torch.float64),\n  'embed_22': tensor([ 2.1752,  2.1752,  2.1752,  2.1752,  2.1752, -0.7170,  2.1752,  2.1752,\n           2.1752,  2.1752,  2.1752,  2.1752,  2.1752,  2.1752,  2.1752,  2.1752,\n           2.1752,  2.1752,  2.1752, -3.9458,  2.1752,  2.1752,  2.1752,  2.1752,\n           2.1752,  2.1752,  2.1752,  2.1752,  2.1752,  2.1752,  2.1752, -3.9458],\n         dtype=torch.float64),\n  'embed_23': tensor([ 1.0343,  1.0343,  1.0343,  1.0343,  1.0343, -3.2511,  1.0343,  1.0343,\n           1.0343,  1.0343,  1.0343,  1.0343,  1.0343,  1.0343,  1.0343,  1.0343,\n           1.0343,  1.0343,  1.0343, -2.9636,  1.0343,  1.0343,  1.0343,  1.0343,\n           1.0343,  1.0343,  1.0343,  1.0343,  1.0343,  1.0343,  1.0343, -2.9636],\n         dtype=torch.float64),\n  'embed_24': tensor([-0.7503, -0.7503, -0.7503, -0.7503, -0.7503, -2.0514, -0.7503, -0.7503,\n          -0.7503, -0.7503, -0.7503, -0.7503, -0.7503, -0.7503, -0.7503, -0.7503,\n          -0.7503, -0.7503, -0.7503,  3.5077, -0.7503, -0.7503, -0.7503, -0.7503,\n          -0.7503, -0.7503, -0.7503, -0.7503, -0.7503, -0.7503, -0.7503,  3.5077],\n         dtype=torch.float64)},\n tensor([[5.],\n         [4.],\n         [5.],\n         [3.],\n         [4.],\n         [2.],\n         [2.],\n         [3.],\n         [3.],\n         [4.],\n         [3.],\n         [4.],\n         [4.],\n         [5.],\n         [3.],\n         [4.],\n         [3.],\n         [4.],\n         [3.],\n         [5.],\n         [3.],\n         [4.],\n         [4.],\n         [3.],\n         [5.],\n         [3.],\n         [4.],\n         [4.],\n         [4.],\n         [5.],\n         [4.],\n         [3.]])]"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(train, 32)\n",
    "z = next(iter(dl))\n",
    "z"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "user_embeds = nn.Embedding(\n",
    "    num_embeddings=max(meta['occupations'])+1,\n",
    "    embedding_dim=25\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 25])"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embeds(z[0]['occupation']).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 1])"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0]['hour'].unsqueeze(-1).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "[10, 16, 12, 7, 1, 3, 4, 8, 17, 0, 2, 9, 19, 18, 15, 11, 20, 13, 5, 14, 6]"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta['occupations']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
