{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchmetrics\n",
    "\n",
    "from deeprec.torch.trainer import Trainer, set_device\n",
    "from deeprec import ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['title_emb_size', 'string_na', 'genres', 'ages', 'occupations', 'user', 'movie', 'city', 'state'])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/metadata.json', 'r') as fp:\n",
    "    meta = json.load(fp)\n",
    "\n",
    "meta.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "class Vocab(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, x):\n",
    "        c = Counter(x)\n",
    "        self.lookup_ = {\n",
    "            str(v).lower(): k for k, v in enumerate([x[0] for x in sorted(c.items(), key=lambda x: x[1], reverse=True)])\n",
    "        }\n",
    "\n",
    "    def transform(self, x):\n",
    "        return [self.lookup_.get(str(xx).lower(), 99999) for xx in x]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "state_enc = Vocab()\n",
    "state_enc.fit(meta['state'])\n",
    "\n",
    "city_enc = Vocab()\n",
    "city_enc.fit(meta['city'])\n",
    "\n",
    "user_enc = Vocab()\n",
    "user_enc.fit(meta['user'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "        user  movie  hour  day_of_week  month  gender  age  occupation  \\\nindex                                                                    \n956151  6036   3132     1            2      4       1   25          15   \n956152  6037   3132     3            2      4       1   45           1   \n956149  5960   3132    17            5      4       1   45           0   \n956150  6016   3132    20            2      4       0   45           1   \n956146  5643   3132     6            6      5       1   35           1   \n\n                  city state  ...  embed_15  embed_16  embed_17  embed_18  \\\nindex                         ...                                           \n956151     Gainesville    FL  ...  0.511667   1.46494  -2.46967 -1.196152   \n956152       Arlington    TX  ...  0.511667   1.46494  -2.46967 -1.196152   \n956149         Slidell    LA  ...  0.511667   1.46494  -2.46967 -1.196152   \n956150       Nashville    TN  ...  0.511667   1.46494  -2.46967 -1.196152   \n956146  Salt Lake City    UT  ...  0.511667   1.46494  -2.46967 -1.196152   \n\n        embed_19  embed_20  embed_21  embed_22  embed_23  embed_24  \nindex                                                               \n956151   -0.7946  -0.09462   2.84776   2.17518   1.03427  -0.75034  \n956152   -0.7946  -0.09462   2.84776   2.17518   1.03427  -0.75034  \n956149   -0.7946  -0.09462   2.84776   2.17518   1.03427  -0.75034  \n956150   -0.7946  -0.09462   2.84776   2.17518   1.03427  -0.75034  \n956146   -0.7946  -0.09462   2.84776   2.17518   1.03427  -0.75034  \n\n[5 rows x 54 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>movie</th>\n      <th>hour</th>\n      <th>day_of_week</th>\n      <th>month</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>occupation</th>\n      <th>city</th>\n      <th>state</th>\n      <th>...</th>\n      <th>embed_15</th>\n      <th>embed_16</th>\n      <th>embed_17</th>\n      <th>embed_18</th>\n      <th>embed_19</th>\n      <th>embed_20</th>\n      <th>embed_21</th>\n      <th>embed_22</th>\n      <th>embed_23</th>\n      <th>embed_24</th>\n    </tr>\n    <tr>\n      <th>index</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>956151</th>\n      <td>6036</td>\n      <td>3132</td>\n      <td>1</td>\n      <td>2</td>\n      <td>4</td>\n      <td>1</td>\n      <td>25</td>\n      <td>15</td>\n      <td>Gainesville</td>\n      <td>FL</td>\n      <td>...</td>\n      <td>0.511667</td>\n      <td>1.46494</td>\n      <td>-2.46967</td>\n      <td>-1.196152</td>\n      <td>-0.7946</td>\n      <td>-0.09462</td>\n      <td>2.84776</td>\n      <td>2.17518</td>\n      <td>1.03427</td>\n      <td>-0.75034</td>\n    </tr>\n    <tr>\n      <th>956152</th>\n      <td>6037</td>\n      <td>3132</td>\n      <td>3</td>\n      <td>2</td>\n      <td>4</td>\n      <td>1</td>\n      <td>45</td>\n      <td>1</td>\n      <td>Arlington</td>\n      <td>TX</td>\n      <td>...</td>\n      <td>0.511667</td>\n      <td>1.46494</td>\n      <td>-2.46967</td>\n      <td>-1.196152</td>\n      <td>-0.7946</td>\n      <td>-0.09462</td>\n      <td>2.84776</td>\n      <td>2.17518</td>\n      <td>1.03427</td>\n      <td>-0.75034</td>\n    </tr>\n    <tr>\n      <th>956149</th>\n      <td>5960</td>\n      <td>3132</td>\n      <td>17</td>\n      <td>5</td>\n      <td>4</td>\n      <td>1</td>\n      <td>45</td>\n      <td>0</td>\n      <td>Slidell</td>\n      <td>LA</td>\n      <td>...</td>\n      <td>0.511667</td>\n      <td>1.46494</td>\n      <td>-2.46967</td>\n      <td>-1.196152</td>\n      <td>-0.7946</td>\n      <td>-0.09462</td>\n      <td>2.84776</td>\n      <td>2.17518</td>\n      <td>1.03427</td>\n      <td>-0.75034</td>\n    </tr>\n    <tr>\n      <th>956150</th>\n      <td>6016</td>\n      <td>3132</td>\n      <td>20</td>\n      <td>2</td>\n      <td>4</td>\n      <td>0</td>\n      <td>45</td>\n      <td>1</td>\n      <td>Nashville</td>\n      <td>TN</td>\n      <td>...</td>\n      <td>0.511667</td>\n      <td>1.46494</td>\n      <td>-2.46967</td>\n      <td>-1.196152</td>\n      <td>-0.7946</td>\n      <td>-0.09462</td>\n      <td>2.84776</td>\n      <td>2.17518</td>\n      <td>1.03427</td>\n      <td>-0.75034</td>\n    </tr>\n    <tr>\n      <th>956146</th>\n      <td>5643</td>\n      <td>3132</td>\n      <td>6</td>\n      <td>6</td>\n      <td>5</td>\n      <td>1</td>\n      <td>35</td>\n      <td>1</td>\n      <td>Salt Lake City</td>\n      <td>UT</td>\n      <td>...</td>\n      <td>0.511667</td>\n      <td>1.46494</td>\n      <td>-2.46967</td>\n      <td>-1.196152</td>\n      <td>-0.7946</td>\n      <td>-0.09462</td>\n      <td>2.84776</td>\n      <td>2.17518</td>\n      <td>1.03427</td>\n      <td>-0.75034</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 54 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('../data/train.parq.gzip').drop('rating', axis=1)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "        rating\nindex         \n956151       5\n956152       4\n956149       5\n956150       3\n956146       4",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rating</th>\n    </tr>\n    <tr>\n      <th>index</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>956151</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>956152</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>956149</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>956150</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>956146</th>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('../data/train.parq.gzip', columns=['rating'])\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "{1, 2, 3, 4, 5}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df['rating'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, filename, state_vocab, city_vocab, user_vocab):\n",
    "        x = pd.read_parquet(filename).drop('rating', axis=1)\n",
    "        y = pd.read_parquet(filename, columns=['rating'])\n",
    "\n",
    "        x['state'] = state_vocab.transform(x['state'])\n",
    "        x['city'] = city_vocab.transform(x['city'])\n",
    "        x['user'] = user_vocab.transform(x['user'])\n",
    "\n",
    "        self.feature_names = x.columns\n",
    "        self.x = x.to_dict('records')\n",
    "        self.y = torch.tensor(y.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "train = MovieDataset('../data/train.parq.gzip', state_vocab=state_enc, city_vocab=city_enc, user_vocab=user_enc)\n",
    "test = MovieDataset('../data/test.parq.gzip', state_vocab=state_enc, city_vocab=city_enc, user_vocab=user_enc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    },
    {
     "data": {
      "text/plain": "Index(['user', 'movie', 'hour', 'day_of_week', 'month', 'gender', 'age',\n       'occupation', 'city', 'state', 'year', 'genre_action',\n       'genre_adventure', 'genre_animation', 'genre_childrens', 'genre_comedy',\n       'genre_crime', 'genre_documentary', 'genre_drama', 'genre_fantasy',\n       'genre_filmnoir', 'genre_horror', 'genre_musical', 'genre_mystery',\n       'genre_romance', 'genre_scifi', 'genre_thriller', 'genre_war',\n       'genre_western', 'embed_0', 'embed_1', 'embed_2', 'embed_3', 'embed_4',\n       'embed_5', 'embed_6', 'embed_7', 'embed_8', 'embed_9', 'embed_10',\n       'embed_11', 'embed_12', 'embed_13', 'embed_14', 'embed_15', 'embed_16',\n       'embed_17', 'embed_18', 'embed_19', 'embed_20', 'embed_21', 'embed_22',\n       'embed_23', 'embed_24'],\n      dtype='object')"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train.feature_names))\n",
    "train.feature_names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'user': tensor([  66, 1566, 1665,   60]),\n  'movie': tensor([3132, 3132, 3132, 3132]),\n  'hour': tensor([ 1,  3, 17, 20]),\n  'day_of_week': tensor([2, 2, 5, 2]),\n  'month': tensor([4, 4, 4, 4]),\n  'gender': tensor([1, 1, 1, 0]),\n  'age': tensor([25, 45, 45, 45]),\n  'occupation': tensor([15,  1,  0,  1]),\n  'city': tensor([   61,    34, 99999,    38]),\n  'state': tensor([    9,     4, 99999, 99999]),\n  'year': tensor([1919, 1919, 1919, 1919]),\n  'genre_action': tensor([0, 0, 0, 0]),\n  'genre_adventure': tensor([0, 0, 0, 0]),\n  'genre_animation': tensor([0, 0, 0, 0]),\n  'genre_childrens': tensor([0, 0, 0, 0]),\n  'genre_comedy': tensor([1, 1, 1, 1]),\n  'genre_crime': tensor([0, 0, 0, 0]),\n  'genre_documentary': tensor([0, 0, 0, 0]),\n  'genre_drama': tensor([0, 0, 0, 0]),\n  'genre_fantasy': tensor([0, 0, 0, 0]),\n  'genre_filmnoir': tensor([0, 0, 0, 0]),\n  'genre_horror': tensor([0, 0, 0, 0]),\n  'genre_musical': tensor([0, 0, 0, 0]),\n  'genre_mystery': tensor([0, 0, 0, 0]),\n  'genre_romance': tensor([0, 0, 0, 0]),\n  'genre_scifi': tensor([0, 0, 0, 0]),\n  'genre_thriller': tensor([0, 0, 0, 0]),\n  'genre_war': tensor([0, 0, 0, 0]),\n  'genre_western': tensor([0, 0, 0, 0]),\n  'embed_0': tensor([-3.2278, -3.2278, -3.2278, -3.2278], dtype=torch.float64),\n  'embed_1': tensor([-0.0905, -0.0905, -0.0905, -0.0905], dtype=torch.float64),\n  'embed_2': tensor([1.2616, 1.2616, 1.2616, 1.2616], dtype=torch.float64),\n  'embed_3': tensor([0.6548, 0.6548, 0.6548, 0.6548], dtype=torch.float64),\n  'embed_4': tensor([0.5871, 0.5871, 0.5871, 0.5871], dtype=torch.float64),\n  'embed_5': tensor([1.1163, 1.1163, 1.1163, 1.1163], dtype=torch.float64),\n  'embed_6': tensor([3.0645, 3.0645, 3.0645, 3.0645], dtype=torch.float64),\n  'embed_7': tensor([-0.3949, -0.3949, -0.3949, -0.3949], dtype=torch.float64),\n  'embed_8': tensor([-1.4985, -1.4985, -1.4985, -1.4985], dtype=torch.float64),\n  'embed_9': tensor([0.7480, 0.7480, 0.7480, 0.7480], dtype=torch.float64),\n  'embed_10': tensor([-0.8427, -0.8427, -0.8427, -0.8427], dtype=torch.float64),\n  'embed_11': tensor([0.5493, 0.5493, 0.5493, 0.5493], dtype=torch.float64),\n  'embed_12': tensor([-11.3576, -11.3576, -11.3576, -11.3576], dtype=torch.float64),\n  'embed_13': tensor([-0.4556, -0.4556, -0.4556, -0.4556], dtype=torch.float64),\n  'embed_14': tensor([-0.5682, -0.5682, -0.5682, -0.5682], dtype=torch.float64),\n  'embed_15': tensor([0.5117, 0.5117, 0.5117, 0.5117], dtype=torch.float64),\n  'embed_16': tensor([1.4649, 1.4649, 1.4649, 1.4649], dtype=torch.float64),\n  'embed_17': tensor([-2.4697, -2.4697, -2.4697, -2.4697], dtype=torch.float64),\n  'embed_18': tensor([-1.1962, -1.1962, -1.1962, -1.1962], dtype=torch.float64),\n  'embed_19': tensor([-0.7946, -0.7946, -0.7946, -0.7946], dtype=torch.float64),\n  'embed_20': tensor([-0.0946, -0.0946, -0.0946, -0.0946], dtype=torch.float64),\n  'embed_21': tensor([2.8478, 2.8478, 2.8478, 2.8478], dtype=torch.float64),\n  'embed_22': tensor([2.1752, 2.1752, 2.1752, 2.1752], dtype=torch.float64),\n  'embed_23': tensor([1.0343, 1.0343, 1.0343, 1.0343], dtype=torch.float64),\n  'embed_24': tensor([-0.7503, -0.7503, -0.7503, -0.7503], dtype=torch.float64)},\n tensor([[5.],\n         [4.],\n         [5.],\n         [3.]])]"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(train, 4)\n",
    "next(iter(dl))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "z = next(iter(dl))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stack_features(inputs, feat):\n",
    "    return torch.stack([v for k, v in inputs.items() if feat in k], 1)\n",
    "\n",
    "\n",
    "stack_features(z[0], 'genre')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "class RecModel(nn.Module):\n",
    "    def __init__(self, metadata, n_features=54):\n",
    "        super().__init__()\n",
    "        self.meta = metadata\n",
    "        self.embed_dims = {\n",
    "            'large': 25,\n",
    "            'med': 7,\n",
    "            'small': 3\n",
    "        }\n",
    "        self.loss_func = nn.MSELoss()\n",
    "\n",
    "        self.user_embeds = nn.Embedding(\n",
    "            num_embeddings=len(meta['user'].keys()) + 1,\n",
    "            embedding_dim=self.embed_dims['large']\n",
    "        )\n",
    "\n",
    "        self.city_embeds = nn.Embedding(\n",
    "            num_embeddings=len(meta['city'].keys()) + 1,\n",
    "            embedding_dim=self.embed_dims['med']\n",
    "        )\n",
    "\n",
    "        self.state_embeds = nn.Embedding(\n",
    "            num_embeddings=len(meta['state'].keys()) + 1,\n",
    "            embedding_dim=self.embed_dims['small']\n",
    "        )\n",
    "\n",
    "        self.age_embeds = nn.Embedding(\n",
    "            num_embeddings=len(meta['ages']) + 1,\n",
    "            embedding_dim=self.embed_dims['small']\n",
    "        )\n",
    "\n",
    "        self.occ_embeds = nn.Embedding(\n",
    "            num_embeddings=len(meta['occupations']) + 1,\n",
    "            embedding_dim=self.embed_dims['small']\n",
    "        )\n",
    "\n",
    "        self.user_model = nn.Sequential(\n",
    "            nn.LazyLinear(out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.LazyLinear(out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_user = torch.concat(\n",
    "            (\n",
    "                self.user_embeds(x['user']),\n",
    "                self.city_embeds(x['city']),\n",
    "                self.state_embeds(x['state']),\n",
    "                self.age_embeds(x['age']),\n",
    "                self.occ_embeds([x['occupation']]),\n",
    "                x['gender'],\n",
    "                x['hour'],\n",
    "                x['day_of_week'],\n",
    "                x['month']\n",
    "            ),\n",
    "            dim=1\n",
    "        )\n",
    "        x = self.model(x_user)\n",
    "        return x\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/15 [00:00<?, ?it/s]\n",
      "Batch:   0%|          | 0/96 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch:   0%|          | 0/15 [00:00<?, ?it/s]\u001B[A\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [44]\u001B[0m, in \u001B[0;36m<cell line: 15>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     10\u001B[0m opt \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdamW(mod\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m)\n\u001B[1;32m     11\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[1;32m     12\u001B[0m     mod, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m15\u001B[39m, device\u001B[38;5;241m=\u001B[39mdevice, log_dir\u001B[38;5;241m=\u001B[39mLOG_DIR, checkpoint_file\u001B[38;5;241m=\u001B[39mLOG_DIR\u001B[38;5;241m.\u001B[39mjoinpath(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel.pt\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[1;32m     13\u001B[0m     optimizer\u001B[38;5;241m=\u001B[39mopt, score_funcs\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmse\u001B[39m\u001B[38;5;124m'\u001B[39m: torchmetrics\u001B[38;5;241m.\u001B[39mMeanSquaredError()}\n\u001B[1;32m     14\u001B[0m )\n\u001B[0;32m---> 15\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [17]\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, train_dl, valid_dl)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m inputs, labels \u001B[38;5;129;01min\u001B[39;00m tqdm\u001B[38;5;241m.\u001B[39mtqdm(train_dl, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBatch\u001B[39m\u001B[38;5;124m'\u001B[39m, leave\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;66;03m# inputs = inputs.to(self.device)\u001B[39;00m\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;66;03m# labels = labels.to(self.device)\u001B[39;00m\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 56\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     57\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mloss_func(logits, labels)\n\u001B[1;32m     58\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/miniforge3/envs/deeprec/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Input \u001B[0;32mIn [43]\u001B[0m, in \u001B[0;36mRecModel.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m     51\u001B[0m     x_user \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mconcat(\n\u001B[1;32m     52\u001B[0m         (\n\u001B[0;32m---> 53\u001B[0m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muser_embeds\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m     54\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcity_embeds(x[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcity\u001B[39m\u001B[38;5;124m'\u001B[39m]),\n\u001B[1;32m     55\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate_embeds(x[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstate\u001B[39m\u001B[38;5;124m'\u001B[39m]),\n\u001B[1;32m     56\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mage_embeds(x[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mage\u001B[39m\u001B[38;5;124m'\u001B[39m]),\n\u001B[1;32m     57\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mocc_embeds([x[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moccupation\u001B[39m\u001B[38;5;124m'\u001B[39m]]),\n\u001B[1;32m     58\u001B[0m             x[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgender\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     59\u001B[0m             x[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhour\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     60\u001B[0m             x[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mday_of_week\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     61\u001B[0m             x[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmonth\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     62\u001B[0m         ),\n\u001B[1;32m     63\u001B[0m         dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     64\u001B[0m     )\n\u001B[1;32m     65\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(x_user)\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m~/miniforge3/envs/deeprec/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniforge3/envs/deeprec/lib/python3.9/site-packages/torch/nn/modules/sparse.py:158\u001B[0m, in \u001B[0;36mEmbedding.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 158\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_norm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/deeprec/lib/python3.9/site-packages/torch/nn/functional.py:2199\u001B[0m, in \u001B[0;36membedding\u001B[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[1;32m   2193\u001B[0m     \u001B[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001B[39;00m\n\u001B[1;32m   2194\u001B[0m     \u001B[38;5;66;03m# XXX: equivalent to\u001B[39;00m\n\u001B[1;32m   2195\u001B[0m     \u001B[38;5;66;03m# with torch.no_grad():\u001B[39;00m\n\u001B[1;32m   2196\u001B[0m     \u001B[38;5;66;03m#   torch.embedding_renorm_\u001B[39;00m\n\u001B[1;32m   2197\u001B[0m     \u001B[38;5;66;03m# remove once script supports set_grad_enabled\u001B[39;00m\n\u001B[1;32m   2198\u001B[0m     _no_grad_embedding_renorm_(weight, \u001B[38;5;28minput\u001B[39m, max_norm, norm_type)\n\u001B[0;32m-> 2199\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mIndexError\u001B[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "NOW = datetime.now().strftime('%Y%m%d-%H%M')\n",
    "LOG_DIR = ROOT.joinpath('runs', NOW)\n",
    "BATCH = 10_000\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=BATCH, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=BATCH)\n",
    "\n",
    "device = set_device()\n",
    "mod = RecModel(metadata=meta)\n",
    "opt = torch.optim.AdamW(mod.parameters(), lr=0.01)\n",
    "trainer = Trainer(\n",
    "    mod, epochs=15, device=device, log_dir=LOG_DIR, checkpoint_file=LOG_DIR.joinpath('model.pt'),\n",
    "    optimizer=opt, score_funcs={'mse': torchmetrics.MeanSquaredError()}\n",
    ")\n",
    "trainer.fit(train_loader, test_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "{e:v for e,v in enumerate(torch.sqrt(torch.tensor(trainer.results['valid_mse'])))}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'user': tensor([   66,  1566,  1665,    60,    30,  2355,  1692,    64,   934,  1067,\n           1065, 99999,   566,  1637,   862,   129,   219,  1960,    17,    28,\n            441,   327,    53,   431,    27,   812,  2028,   803,   137, 99999,\n           1158,   682]),\n  'movie': tensor([3132, 3132, 3132, 3132, 3132, 2821, 3132, 3132, 3132, 3132, 3132, 3132,\n          3132, 3132, 3132, 3132, 3132, 3132, 3132, 2823, 3132, 3132, 3132, 3132,\n          3132, 3132, 3132, 3132, 3132, 3132, 3132, 2823]),\n  'hour': tensor([ 1,  3, 17, 20,  6, 21,  6,  7, 23, 23, 12, 21, 21, 21,  0,  0,  2, 14,\n          15, 18,  4, 13, 16, 16, 17,  8, 21,  2,  3,  4,  6,  8]),\n  'day_of_week': tensor([2, 2, 5, 2, 6, 2, 0, 5, 3, 3, 2, 5, 4, 5, 4, 5, 0, 3, 3, 0, 6, 3, 0, 1,\n          5, 1, 2, 4, 1, 0, 2, 2]),\n  'month': tensor([ 4,  4,  4,  4,  5,  5,  6,  6,  6,  6,  7,  7,  7,  7,  8,  8,  8,  8,\n           8,  8,  9,  9,  9,  9,  9, 10, 10, 11, 11, 11, 11, 11]),\n  'gender': tensor([1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n          1, 1, 0, 1, 1, 1, 1, 1]),\n  'age': tensor([25, 45, 45, 45, 35, 35, 50, 25, 56, 35, 35, 25, 35, 45, 25, 56, 45, 45,\n          25, 25, 35, 45, 50, 25, 25, 35, 45, 56, 45, 50, 50, 45]),\n  'occupation': tensor([15,  1,  0,  1,  1, 14,  1,  7, 20,  0,  4, 14,  6,  1,  3, 14,  1,  3,\n          19,  4, 20, 20,  6, 20, 14, 20, 11,  7,  6, 14, 20,  2]),\n  'city': tensor([   61,    34, 99999,    38,    59, 99999,   127,     6,   242,    35,\n          99999,     2,    15, 99999,     7,    94,    14,   416,   175,    13,\n            136,   195,    51,   135,   187,     5,     2, 99999,    65,    27,\n             17,   260]),\n  'state': tensor([    9,     4, 99999, 99999, 99999, 99999,     8,     0,     0,    13,\n              6,     0,     7,    10,     0,     0,     6,     7,     1,     4,\n              0, 99999,     4,     0,     0,     8,     0,     5,     5, 99999,\n              1, 99999]),\n  'year': tensor([1919, 1919, 1919, 1919, 1919, 1919, 1919, 1919, 1919, 1919, 1919, 1919,\n          1919, 1919, 1919, 1919, 1919, 1919, 1919, 1919, 1919, 1919, 1919, 1919,\n          1919, 1919, 1919, 1919, 1919, 1919, 1919, 1919]),\n  'genre_action': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 1]),\n  'genre_adventure': tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_animation': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_childrens': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_comedy': tensor([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n          1, 1, 1, 1, 1, 1, 1, 0]),\n  'genre_crime': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_documentary': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_drama': tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 1]),\n  'genre_fantasy': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_filmnoir': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_horror': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_musical': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_mystery': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_romance': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_scifi': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_thriller': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_war': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'genre_western': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'embed_0': tensor([-3.2278, -3.2278, -3.2278, -3.2278, -3.2278, -1.4783, -3.2278, -3.2278,\n          -3.2278, -3.2278, -3.2278, -3.2278, -3.2278, -3.2278, -3.2278, -3.2278,\n          -3.2278, -3.2278, -3.2278,  5.3274, -3.2278, -3.2278, -3.2278, -3.2278,\n          -3.2278, -3.2278, -3.2278, -3.2278, -3.2278, -3.2278, -3.2278,  5.3274],\n         dtype=torch.float64),\n  'embed_1': tensor([-0.0905, -0.0905, -0.0905, -0.0905, -0.0905, -0.0899, -0.0905, -0.0905,\n          -0.0905, -0.0905, -0.0905, -0.0905, -0.0905, -0.0905, -0.0905, -0.0905,\n          -0.0905, -0.0905, -0.0905, -1.1371, -0.0905, -0.0905, -0.0905, -0.0905,\n          -0.0905, -0.0905, -0.0905, -0.0905, -0.0905, -0.0905, -0.0905, -1.1371],\n         dtype=torch.float64),\n  'embed_2': tensor([ 1.2616,  1.2616,  1.2616,  1.2616,  1.2616, -0.3488,  1.2616,  1.2616,\n           1.2616,  1.2616,  1.2616,  1.2616,  1.2616,  1.2616,  1.2616,  1.2616,\n           1.2616,  1.2616,  1.2616,  0.0224,  1.2616,  1.2616,  1.2616,  1.2616,\n           1.2616,  1.2616,  1.2616,  1.2616,  1.2616,  1.2616,  1.2616,  0.0224],\n         dtype=torch.float64),\n  'embed_3': tensor([ 0.6548,  0.6548,  0.6548,  0.6548,  0.6548, -0.7970,  0.6548,  0.6548,\n           0.6548,  0.6548,  0.6548,  0.6548,  0.6548,  0.6548,  0.6548,  0.6548,\n           0.6548,  0.6548,  0.6548, -1.4486,  0.6548,  0.6548,  0.6548,  0.6548,\n           0.6548,  0.6548,  0.6548,  0.6548,  0.6548,  0.6548,  0.6548, -1.4486],\n         dtype=torch.float64),\n  'embed_4': tensor([ 0.5871,  0.5871,  0.5871,  0.5871,  0.5871,  2.0920,  0.5871,  0.5871,\n           0.5871,  0.5871,  0.5871,  0.5871,  0.5871,  0.5871,  0.5871,  0.5871,\n           0.5871,  0.5871,  0.5871, -2.0371,  0.5871,  0.5871,  0.5871,  0.5871,\n           0.5871,  0.5871,  0.5871,  0.5871,  0.5871,  0.5871,  0.5871, -2.0371],\n         dtype=torch.float64),\n  'embed_5': tensor([ 1.1163,  1.1163,  1.1163,  1.1163,  1.1163, -1.2675,  1.1163,  1.1163,\n           1.1163,  1.1163,  1.1163,  1.1163,  1.1163,  1.1163,  1.1163,  1.1163,\n           1.1163,  1.1163,  1.1163,  3.3954,  1.1163,  1.1163,  1.1163,  1.1163,\n           1.1163,  1.1163,  1.1163,  1.1163,  1.1163,  1.1163,  1.1163,  3.3954],\n         dtype=torch.float64),\n  'embed_6': tensor([ 3.0645,  3.0645,  3.0645,  3.0645,  3.0645,  3.7290,  3.0645,  3.0645,\n           3.0645,  3.0645,  3.0645,  3.0645,  3.0645,  3.0645,  3.0645,  3.0645,\n           3.0645,  3.0645,  3.0645, -1.7011,  3.0645,  3.0645,  3.0645,  3.0645,\n           3.0645,  3.0645,  3.0645,  3.0645,  3.0645,  3.0645,  3.0645, -1.7011],\n         dtype=torch.float64),\n  'embed_7': tensor([-0.3949, -0.3949, -0.3949, -0.3949, -0.3949, -0.3805, -0.3949, -0.3949,\n          -0.3949, -0.3949, -0.3949, -0.3949, -0.3949, -0.3949, -0.3949, -0.3949,\n          -0.3949, -0.3949, -0.3949, -4.7617, -0.3949, -0.3949, -0.3949, -0.3949,\n          -0.3949, -0.3949, -0.3949, -0.3949, -0.3949, -0.3949, -0.3949, -4.7617],\n         dtype=torch.float64),\n  'embed_8': tensor([-1.4985, -1.4985, -1.4985, -1.4985, -1.4985,  0.2837, -1.4985, -1.4985,\n          -1.4985, -1.4985, -1.4985, -1.4985, -1.4985, -1.4985, -1.4985, -1.4985,\n          -1.4985, -1.4985, -1.4985,  0.2152, -1.4985, -1.4985, -1.4985, -1.4985,\n          -1.4985, -1.4985, -1.4985, -1.4985, -1.4985, -1.4985, -1.4985,  0.2152],\n         dtype=torch.float64),\n  'embed_9': tensor([ 0.7480,  0.7480,  0.7480,  0.7480,  0.7480,  0.2406,  0.7480,  0.7480,\n           0.7480,  0.7480,  0.7480,  0.7480,  0.7480,  0.7480,  0.7480,  0.7480,\n           0.7480,  0.7480,  0.7480, -1.0419,  0.7480,  0.7480,  0.7480,  0.7480,\n           0.7480,  0.7480,  0.7480,  0.7480,  0.7480,  0.7480,  0.7480, -1.0419],\n         dtype=torch.float64),\n  'embed_10': tensor([-0.8427, -0.8427, -0.8427, -0.8427, -0.8427,  0.0801, -0.8427, -0.8427,\n          -0.8427, -0.8427, -0.8427, -0.8427, -0.8427, -0.8427, -0.8427, -0.8427,\n          -0.8427, -0.8427, -0.8427, -0.6382, -0.8427, -0.8427, -0.8427, -0.8427,\n          -0.8427, -0.8427, -0.8427, -0.8427, -0.8427, -0.8427, -0.8427, -0.6382],\n         dtype=torch.float64),\n  'embed_11': tensor([ 0.5493,  0.5493,  0.5493,  0.5493,  0.5493, -0.9175,  0.5493,  0.5493,\n           0.5493,  0.5493,  0.5493,  0.5493,  0.5493,  0.5493,  0.5493,  0.5493,\n           0.5493,  0.5493,  0.5493,  5.7177,  0.5493,  0.5493,  0.5493,  0.5493,\n           0.5493,  0.5493,  0.5493,  0.5493,  0.5493,  0.5493,  0.5493,  5.7177],\n         dtype=torch.float64),\n  'embed_12': tensor([-11.3576, -11.3576, -11.3576, -11.3576, -11.3576, -12.9007, -11.3576,\n          -11.3576, -11.3576, -11.3576, -11.3576, -11.3576, -11.3576, -11.3576,\n          -11.3576, -11.3576, -11.3576, -11.3576, -11.3576, -18.5922, -11.3576,\n          -11.3576, -11.3576, -11.3576, -11.3576, -11.3576, -11.3576, -11.3576,\n          -11.3576, -11.3576, -11.3576, -18.5922], dtype=torch.float64),\n  'embed_13': tensor([-0.4556, -0.4556, -0.4556, -0.4556, -0.4556,  0.1208, -0.4556, -0.4556,\n          -0.4556, -0.4556, -0.4556, -0.4556, -0.4556, -0.4556, -0.4556, -0.4556,\n          -0.4556, -0.4556, -0.4556, -3.5370, -0.4556, -0.4556, -0.4556, -0.4556,\n          -0.4556, -0.4556, -0.4556, -0.4556, -0.4556, -0.4556, -0.4556, -3.5370],\n         dtype=torch.float64),\n  'embed_14': tensor([-0.5682, -0.5682, -0.5682, -0.5682, -0.5682, -1.9190, -0.5682, -0.5682,\n          -0.5682, -0.5682, -0.5682, -0.5682, -0.5682, -0.5682, -0.5682, -0.5682,\n          -0.5682, -0.5682, -0.5682,  0.1743, -0.5682, -0.5682, -0.5682, -0.5682,\n          -0.5682, -0.5682, -0.5682, -0.5682, -0.5682, -0.5682, -0.5682,  0.1743],\n         dtype=torch.float64),\n  'embed_15': tensor([0.5117, 0.5117, 0.5117, 0.5117, 0.5117, 1.6354, 0.5117, 0.5117, 0.5117,\n          0.5117, 0.5117, 0.5117, 0.5117, 0.5117, 0.5117, 0.5117, 0.5117, 0.5117,\n          0.5117, 1.5627, 0.5117, 0.5117, 0.5117, 0.5117, 0.5117, 0.5117, 0.5117,\n          0.5117, 0.5117, 0.5117, 0.5117, 1.5627], dtype=torch.float64),\n  'embed_16': tensor([1.4649, 1.4649, 1.4649, 1.4649, 1.4649, 0.3634, 1.4649, 1.4649, 1.4649,\n          1.4649, 1.4649, 1.4649, 1.4649, 1.4649, 1.4649, 1.4649, 1.4649, 1.4649,\n          1.4649, 4.9485, 1.4649, 1.4649, 1.4649, 1.4649, 1.4649, 1.4649, 1.4649,\n          1.4649, 1.4649, 1.4649, 1.4649, 4.9485], dtype=torch.float64),\n  'embed_17': tensor([-2.4697, -2.4697, -2.4697, -2.4697, -2.4697, -1.5919, -2.4697, -2.4697,\n          -2.4697, -2.4697, -2.4697, -2.4697, -2.4697, -2.4697, -2.4697, -2.4697,\n          -2.4697, -2.4697, -2.4697,  2.8856, -2.4697, -2.4697, -2.4697, -2.4697,\n          -2.4697, -2.4697, -2.4697, -2.4697, -2.4697, -2.4697, -2.4697,  2.8856],\n         dtype=torch.float64),\n  'embed_18': tensor([-1.1962, -1.1962, -1.1962, -1.1962, -1.1962,  0.7238, -1.1962, -1.1962,\n          -1.1962, -1.1962, -1.1962, -1.1962, -1.1962, -1.1962, -1.1962, -1.1962,\n          -1.1962, -1.1962, -1.1962, -5.2075, -1.1962, -1.1962, -1.1962, -1.1962,\n          -1.1962, -1.1962, -1.1962, -1.1962, -1.1962, -1.1962, -1.1962, -5.2075],\n         dtype=torch.float64),\n  'embed_19': tensor([-7.9460e-01, -7.9460e-01, -7.9460e-01, -7.9460e-01, -7.9460e-01,\n           2.7999e-04, -7.9460e-01, -7.9460e-01, -7.9460e-01, -7.9460e-01,\n          -7.9460e-01, -7.9460e-01, -7.9460e-01, -7.9460e-01, -7.9460e-01,\n          -7.9460e-01, -7.9460e-01, -7.9460e-01, -7.9460e-01, -2.8623e+00,\n          -7.9460e-01, -7.9460e-01, -7.9460e-01, -7.9460e-01, -7.9460e-01,\n          -7.9460e-01, -7.9460e-01, -7.9460e-01, -7.9460e-01, -7.9460e-01,\n          -7.9460e-01, -2.8623e+00], dtype=torch.float64),\n  'embed_20': tensor([-0.0946, -0.0946, -0.0946, -0.0946, -0.0946,  0.6792, -0.0946, -0.0946,\n          -0.0946, -0.0946, -0.0946, -0.0946, -0.0946, -0.0946, -0.0946, -0.0946,\n          -0.0946, -0.0946, -0.0946, -1.1122, -0.0946, -0.0946, -0.0946, -0.0946,\n          -0.0946, -0.0946, -0.0946, -0.0946, -0.0946, -0.0946, -0.0946, -1.1122],\n         dtype=torch.float64),\n  'embed_21': tensor([2.8478, 2.8478, 2.8478, 2.8478, 2.8478, 2.4738, 2.8478, 2.8478, 2.8478,\n          2.8478, 2.8478, 2.8478, 2.8478, 2.8478, 2.8478, 2.8478, 2.8478, 2.8478,\n          2.8478, 4.7896, 2.8478, 2.8478, 2.8478, 2.8478, 2.8478, 2.8478, 2.8478,\n          2.8478, 2.8478, 2.8478, 2.8478, 4.7896], dtype=torch.float64),\n  'embed_22': tensor([ 2.1752,  2.1752,  2.1752,  2.1752,  2.1752, -0.7170,  2.1752,  2.1752,\n           2.1752,  2.1752,  2.1752,  2.1752,  2.1752,  2.1752,  2.1752,  2.1752,\n           2.1752,  2.1752,  2.1752, -3.9458,  2.1752,  2.1752,  2.1752,  2.1752,\n           2.1752,  2.1752,  2.1752,  2.1752,  2.1752,  2.1752,  2.1752, -3.9458],\n         dtype=torch.float64),\n  'embed_23': tensor([ 1.0343,  1.0343,  1.0343,  1.0343,  1.0343, -3.2511,  1.0343,  1.0343,\n           1.0343,  1.0343,  1.0343,  1.0343,  1.0343,  1.0343,  1.0343,  1.0343,\n           1.0343,  1.0343,  1.0343, -2.9636,  1.0343,  1.0343,  1.0343,  1.0343,\n           1.0343,  1.0343,  1.0343,  1.0343,  1.0343,  1.0343,  1.0343, -2.9636],\n         dtype=torch.float64),\n  'embed_24': tensor([-0.7503, -0.7503, -0.7503, -0.7503, -0.7503, -2.0514, -0.7503, -0.7503,\n          -0.7503, -0.7503, -0.7503, -0.7503, -0.7503, -0.7503, -0.7503, -0.7503,\n          -0.7503, -0.7503, -0.7503,  3.5077, -0.7503, -0.7503, -0.7503, -0.7503,\n          -0.7503, -0.7503, -0.7503, -0.7503, -0.7503, -0.7503, -0.7503,  3.5077],\n         dtype=torch.float64)},\n tensor([[5.],\n         [4.],\n         [5.],\n         [3.],\n         [4.],\n         [2.],\n         [2.],\n         [3.],\n         [3.],\n         [4.],\n         [3.],\n         [4.],\n         [4.],\n         [5.],\n         [3.],\n         [4.],\n         [3.],\n         [4.],\n         [3.],\n         [5.],\n         [3.],\n         [4.],\n         [4.],\n         [3.],\n         [5.],\n         [3.],\n         [4.],\n         [4.],\n         [4.],\n         [5.],\n         [4.],\n         [3.]])]"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(train, 32)\n",
    "z = next(iter(dl))\n",
    "z"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "user_embeds = nn.Embedding(\n",
    "    num_embeddings=len(meta['user'].keys()) + 1,\n",
    "    embedding_dim=25\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [53]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43muser_embeds\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m99999\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/deeprec/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniforge3/envs/deeprec/lib/python3.9/site-packages/torch/nn/modules/sparse.py:158\u001B[0m, in \u001B[0;36mEmbedding.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 158\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_norm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/deeprec/lib/python3.9/site-packages/torch/nn/functional.py:2199\u001B[0m, in \u001B[0;36membedding\u001B[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[1;32m   2193\u001B[0m     \u001B[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001B[39;00m\n\u001B[1;32m   2194\u001B[0m     \u001B[38;5;66;03m# XXX: equivalent to\u001B[39;00m\n\u001B[1;32m   2195\u001B[0m     \u001B[38;5;66;03m# with torch.no_grad():\u001B[39;00m\n\u001B[1;32m   2196\u001B[0m     \u001B[38;5;66;03m#   torch.embedding_renorm_\u001B[39;00m\n\u001B[1;32m   2197\u001B[0m     \u001B[38;5;66;03m# remove once script supports set_grad_enabled\u001B[39;00m\n\u001B[1;32m   2198\u001B[0m     _no_grad_embedding_renorm_(weight, \u001B[38;5;28minput\u001B[39m, max_norm, norm_type)\n\u001B[0;32m-> 2199\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mIndexError\u001B[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "user_embeds(torch.tensor([99999]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
