{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dad20df-b777-4d12-aca7-0f772d9c29ab",
   "metadata": {},
   "source": [
    "# 4.2 Online Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1, 
   "id": "6e90bd81-fd06-4319-94e9-aff8f73e2574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca9ecd3-9aa9-4b3d-a91a-98a3a94f0efd",
   "metadata": {},
   "source": [
    "Loading data and metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2, 
   "id": "3b127446-5fcc-4f1c-bbe8-7dc07ee9d9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../local_data/train_data.csv', header=0)\n",
    "test_df = pd.read_csv('../local_data/test_data.csv', header=0)\n",
    "with open('../local_data/metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3, 
   "id": "0efc4c13-52e4-4276-8db9-1e321476a658",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users = [str(int(i)) for i in metadata['users']]\n",
    "all_movies = [str(int(i)) for i in metadata['movies']]\n",
    "all_cities = metadata['cities']\n",
    "all_states = metadata['states']\n",
    "all_ages = [str(int(i)) for i in metadata['ages']]\n",
    "all_occupations = [str(int(i)) for i in metadata['occupations']]\n",
    "all_genres = metadata['genres']\n",
    "title_emb_len = metadata['title_emb_size']\n",
    "na_value = metadata['string_na']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4, 
   "id": "de8bf566-3244-449d-91e0-28039fdd2c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_candidates = tf.data.Dataset.from_tensor_slices({'movie': train_df['movie'].unique()}).map(lambda x: x['movie']).batch(200).map(tf.strings.as_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b902b968-e556-4ed9-adca-461719d70980",
   "metadata": {},
   "source": [
    "We will now build our online Feature Store, where we will keep all the features we need about our movies which are required for our model. In real life, this is a low-latency database, here we'll use a Pandas `DataFrame` for simplicity. The concept remains the same.\n",
    "\n",
    "Each row in our database will be a unique movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5, 
   "id": "f204ea15-72fb-4b3f-8322-15cf69210641",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_db = pd.concat([train_df, test_df]).drop(['user','city','state','gender','age','occupation','hour','day','month','rating'], axis=1)\n",
    "movies_db = movies_db.groupby('movie').first()\n",
    "movies_db['movie'] = movies_db.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6, 
   "id": "4964b8e4-eee1-449a-8edf-a07abd243cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_features(movies_list):\n",
    "    df = movies_db.loc[movies_list,:]\n",
    "    d = {k:v.to_numpy() for k,v in dict(df).items()}\n",
    "    d['genres'] = np.transpose(np.array([d[x] for x in all_genres]))\n",
    "    d['title_emb'] = np.transpose(np.array([d[f'title_emb_{i}'] for i in range(title_emb_len)]))\n",
    "    for x in all_genres + [f'title_emb_{i}' for i in range(title_emb_len)]:\n",
    "        d.pop(x)\n",
    "    d.update({k:np.expand_dims(np.vstack(v), axis=0) for k,v in d.items()})\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80413c1-f160-472c-a848-0aff254e4d38",
   "metadata": {},
   "source": [
    "The following are our ranking and retrieval models, copy-pasted from project #3.2 and #4.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7, 
   "id": "3f7db4e7-eaba-4687-880a-d629da5cb951",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingPredictionModel(tfrs.models.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        tower_last_layer_size = 50\n",
    "        large_embedding_size = 25\n",
    "        medium_embedding_size = 5\n",
    "        small_embedding_size = 3\n",
    "        \n",
    "        # User tower\n",
    "        \n",
    "        self.user_input = tf.keras.Input(shape=(1,), dtype=tf.string, name='user_input')\n",
    "        self.user_sl = tf.keras.layers.StringLookup(vocabulary=all_users, name='user_string_lookup')(self.user_input)\n",
    "        self.user_emb = tf.squeeze(tf.keras.layers.Embedding(len(all_users)+1, large_embedding_size, name='user_emb')(self.user_sl), axis=1)\n",
    "        \n",
    "        self.city_input = tf.keras.Input(shape=(1,), dtype=tf.string, name='city_input')\n",
    "        self.city_sl = tf.keras.layers.StringLookup(vocabulary=all_cities, mask_token=na_value, name='city_string_lookup')(self.city_input)\n",
    "        self.city_emb = tf.squeeze(tf.keras.layers.Embedding(len(all_cities)+2, medium_embedding_size, name='city_emb')(self.city_sl), axis=1)\n",
    "        \n",
    "        self.state_input = tf.keras.Input(shape=(1,), dtype=tf.string, name='state_input')\n",
    "        self.state_sl = tf.keras.layers.StringLookup(vocabulary=all_states, mask_token=na_value, name='state_string_lookup')(self.state_input)\n",
    "        self.state_emb = tf.squeeze(tf.keras.layers.Embedding(len(all_states)+2, small_embedding_size, name='state_emb')(self.state_sl), axis=1)\n",
    "        \n",
    "        self.age_input = tf.keras.Input(shape=(1,), dtype=tf.string, name='age_input')\n",
    "        self.age_sl = tf.keras.layers.StringLookup(vocabulary=all_ages, num_oov_indices=0, name='age_string_lookup')(self.age_input)\n",
    "        self.age_emb = tf.squeeze(tf.keras.layers.Embedding(len(all_ages), small_embedding_size, name='age_emb')(self.age_sl), axis=1)\n",
    "        \n",
    "        self.occupation_input = tf.keras.Input(shape=(1,), dtype=tf.string, name='occupation_input')\n",
    "        self.occupation_sl = tf.keras.layers.StringLookup(vocabulary=all_occupations, num_oov_indices=0, name='occupation_string_lookup')(self.occupation_input)\n",
    "        self.occupation_emb = tf.squeeze(tf.keras.layers.Embedding(len(all_occupations), small_embedding_size, name='occupation_emb')(self.occupation_sl), axis=1)\n",
    "        \n",
    "        self.gender_input = tf.keras.Input(shape=(1,), name='gender_input')\n",
    "        self.hour_input = tf.keras.Input(shape=(1,), name='hour_input')\n",
    "        self.day_input = tf.keras.Input(shape=(1,), name='day_input')\n",
    "        self.month_input = tf.keras.Input(shape=(1,), name='month_input')\n",
    "        \n",
    "        self.user_merged = tf.keras.layers.concatenate([self.user_emb, self.city_emb, self.state_emb, self.age_emb, \n",
    "                                                        self.occupation_emb, self.gender_input, self.hour_input,\n",
    "                                                        self.day_input, self.month_input], \n",
    "                                                       axis=-1, name='user_merged')\n",
    "        self.user_dense = tf.keras.layers.Dense(100, activation='relu', name='user_dense')(self.user_merged)\n",
    "        self.user_last_layer = tf.keras.layers.Dense(tower_last_layer_size, activation='relu', name='user_last_layer')(self.user_dense)\n",
    "        \n",
    "        # Movie tower\n",
    "        \n",
    "        self.movie_input = tf.keras.Input(shape=(None,1), dtype=tf.string, name='movie_input')\n",
    "        self.movie_sl = tf.keras.layers.StringLookup(vocabulary=all_movies, name='movie_string_lookup')(self.movie_input)\n",
    "        self.movie_emb = tf.squeeze(tf.keras.layers.Embedding(len(all_movies)+1, large_embedding_size, name='movie_emb')(self.movie_sl), axis=2)\n",
    "        \n",
    "        self.title_input = tf.keras.Input(shape=(None,title_emb_len), name='title_input')\n",
    "        self.title_dense = tf.keras.layers.Dense(title_emb_len, activation='softmax', name='title_softmax')(self.title_input)\n",
    "        \n",
    "        self.genres_input = tf.keras.Input(shape=(None,len(all_genres)), name='genres_input')\n",
    "        self.year_input = tf.keras.Input(shape=(None,1), name='year_input')\n",
    "        \n",
    "        self.movie_merged = tf.keras.layers.concatenate([self.movie_emb, self.title_dense, self.genres_input, self.year_input] ,axis=-1, name='movie_merged')\n",
    "        self.movie_dense = tf.keras.layers.Dense(100, activation='relu', name='movie_dense')(self.movie_merged)\n",
    "        self.movie_last_layer = tf.keras.layers.Dense(tower_last_layer_size, activation='relu', name='movie_last_layer')(self.movie_dense)\n",
    "        \n",
    "        # Combining towers\n",
    "        \n",
    "        self.towers_multiplied = tf.keras.layers.Multiply(name='towers_multiplied')([tf.expand_dims(self.user_last_layer, axis=2), \n",
    "                                                                                     tf.transpose(self.movie_last_layer, perm=[0,2,1])])\n",
    "        self.towers_dense1 = tf.keras.layers.Dense(40, activation='relu', name='towers_dense1')(tf.transpose(self.towers_multiplied, perm=[0,2,1]))\n",
    "        self.towers_dense2 = tf.keras.layers.Dense(20, activation='relu', name='towers_dense2')(self.towers_dense1)\n",
    "        self.output_node = tf.keras.layers.Dense(1, name='output_node')(self.towers_dense2)\n",
    "        \n",
    "        # Model definition\n",
    "        \n",
    "        self.model = tf.keras.Model(inputs={'user': self.user_input, \n",
    "                                            'city': self.city_input,\n",
    "                                            'state': self.state_input,\n",
    "                                            'age': self.age_input,\n",
    "                                            'occupation': self.occupation_input,\n",
    "                                            'gender': self.gender_input,\n",
    "                                            'hour': self.hour_input,\n",
    "                                            'day': self.day_input,\n",
    "                                            'month': self.month_input,\n",
    "                                            'movie': self.movie_input,\n",
    "                                            'title': self.title_input,\n",
    "                                            'genres': self.genres_input,\n",
    "                                            'year': self.year_input\n",
    "                                            }, \n",
    "                                    outputs=self.output_node)\n",
    "        \n",
    "        self.task = tfrs.tasks.Ranking(\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "        \n",
    "    def call(self, features):\n",
    "        return self.model({'user': tf.strings.as_string(features[\"user\"]), \n",
    "                           'city': features[\"city\"], \n",
    "                           'state': features[\"state\"],\n",
    "                           'age': tf.strings.as_string(features[\"age\"]),\n",
    "                           'occupation': tf.strings.as_string(features[\"occupation\"]), \n",
    "                           'gender': features[\"gender\"],\n",
    "                           'hour': features[\"hour\"],\n",
    "                           'day': features[\"day\"],\n",
    "                           'month': features[\"month\"],\n",
    "                           'movie': tf.strings.as_string(features[\"movie\"]),\n",
    "                           'title': features[\"title_emb\"],\n",
    "                           'genres': features[\"genres\"],\n",
    "                           'year': features[\"movie_year\"]\n",
    "                           })\n",
    "    \n",
    "    def compute_loss(self, features_dict, training=False):\n",
    "        labels = features_dict[\"rating\"]\n",
    "        predictions = self(features_dict)\n",
    "        return self.task(labels=labels, predictions=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8, 
   "id": "7e8e350d-7d1f-4b84-afc1-0dc927de4710",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoviesRetrievalModel(tfrs.models.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        large_embedding_size = 20\n",
    "        medium_embedding_size = 5\n",
    "        small_embedding_size = 3\n",
    "        last_layer_size = 20\n",
    "        \n",
    "        # User Model\n",
    "        \n",
    "        self.user_input = tf.keras.Input(shape=(1,), dtype=tf.string, name='user_input')\n",
    "        self.user_sl = tf.keras.layers.StringLookup(vocabulary=all_users, name='user_string_lookup')(self.user_input)\n",
    "        self.user_emb = tf.squeeze(tf.keras.layers.Embedding(len(all_users)+1, large_embedding_size, name='user_emb')(self.user_sl), axis=1)\n",
    "        \n",
    "        self.city_input = tf.keras.Input(shape=(1,), dtype=tf.string, name='city_input')\n",
    "        self.city_sl = tf.keras.layers.StringLookup(vocabulary=all_cities, mask_token=na_value, name='city_string_lookup')(self.city_input)\n",
    "        self.city_emb = tf.squeeze(tf.keras.layers.Embedding(len(all_cities)+2, medium_embedding_size, name='city_emb')(self.city_sl), axis=1)\n",
    "        \n",
    "        self.state_input = tf.keras.Input(shape=(1,), dtype=tf.string, name='state_input')\n",
    "        self.state_sl = tf.keras.layers.StringLookup(vocabulary=all_states, mask_token=na_value, name='state_string_lookup')(self.state_input)\n",
    "        self.state_emb = tf.squeeze(tf.keras.layers.Embedding(len(all_states)+2, small_embedding_size, name='state_emb')(self.state_sl), axis=1)\n",
    "        \n",
    "        self.user_merged = tf.keras.layers.concatenate([self.user_emb, self.city_emb, self.state_emb], \n",
    "                                                       axis=-1, name='user_merged')\n",
    "        self.user_dense = tf.keras.layers.Dense(last_layer_size, activation='relu', name='user_dense')(self.user_merged)\n",
    "        \n",
    "        self.user_model = tf.keras.Model(inputs={'user': self.user_input,\n",
    "                                                 'city': self.city_input,\n",
    "                                                 'state': self.state_input},\n",
    "                                         outputs=self.user_dense)\n",
    "        \n",
    "        \n",
    "        # Movie Model\n",
    "        \n",
    "        self.movie_input = tf.keras.Input(shape=(1,), dtype=tf.string, name='movie_input')\n",
    "        self.movie_sl = tf.keras.layers.StringLookup(vocabulary=all_movies, name='movie_string_lookup')(self.movie_input)\n",
    "        self.movie_emb = tf.squeeze(tf.keras.layers.Embedding(len(all_movies)+1, last_layer_size, name='movie_emb')(self.movie_sl), axis=1)\n",
    "        \n",
    "        self.movie_model = tf.keras.Model(inputs={'movie': self.movie_input},\n",
    "                                          outputs=self.movie_emb)\n",
    "        \n",
    "        \n",
    "        # Task\n",
    "        \n",
    "        task_candidates = movies_candidates.map(self.movie_model)  \n",
    "        top_k_metrics = [tf.keras.metrics.TopKCategoricalAccuracy(k=x, name=f'top_{x}_categorical_accuracy') for x in [10, 100]]\n",
    "        task_metric = tfrs.metrics.FactorizedTopK(candidates=task_candidates, metrics=top_k_metrics)\n",
    "        self.task = tfrs.tasks.Retrieval(metrics=task_metric)  # Default loss: tf.keras.losses.CategoricalCrossentropy\n",
    "        \n",
    "    \n",
    "    def compute_loss(self, features, training=False):\n",
    "        return self.task(\n",
    "            self.user_model({'user': tf.strings.as_string(features[\"user\"]), \n",
    "                             'city': features[\"city\"],\n",
    "                             'state': features[\"state\"]}),\n",
    "            self.movie_model(tf.strings.as_string(features[\"movie\"]))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9, 
   "id": "a3d2cacd-a849-40c5-9c55-3387f62d47b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_model = MoviesRetrievalModel()\n",
    "retrieval_model.compile(optimizer=tf.keras.optimizers.Adagrad())\n",
    "ranking_model = RatingPredictionModel()\n",
    "ranking_model.compile(optimizer=tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3529f6b1-13fd-4a00-abbd-6b39400f2d2f",
   "metadata": {},
   "source": [
    "Loading saved weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10, 
   "id": "f10f9592-744b-4c0c-8280-fddecb06b123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x164fc1c40>"
      ]
     },
     "execution_count": 10, 
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_model.load_weights('weights_4_1/p41')\n",
    "ranking_model.load_weights('../project_3/weights_3_2/p32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54816c37-45f2-45b6-bb58-2998abea9778",
   "metadata": {},
   "source": [
    "Creating our retrieval layer, which will return the top 100 movies from the entire movies dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11, 
   "id": "863efa94-47e3-4925-ae5d-70cd0baa1757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x1655712e0>"
      ]
     },
     "execution_count": 11, 
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval = tfrs.layers.factorized_top_k.BruteForce(retrieval_model.user_model, k=100)\n",
    "retrieval.index_from_dataset(\n",
    "  tf.data.Dataset.zip((movies_candidates, movies_candidates.map(retrieval_model.movie_model)))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3004ccf8-83ae-4858-8b66-29f40ade1199",
   "metadata": {},
   "source": [
    "## Online predictions\n",
    "\n",
    "The following code mimics an online prediction process. The user below enters our website, and we would like to recommend the best 10 movies her. The retrieval will narrow down the almost-4000 movies to only 100, and the ranking system will then predict their ratings by that user, from which we will display only the top 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12, 
   "id": "1b01c973-f663-4233-bc36-75db578c2ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': 6040,\n",
       " 'city': 'Astoria',\n",
       " 'state': 'NY',\n",
       " 'gender': 0.0,\n",
       " 'age': 25,\n",
       " 'occupation': 6,\n",
       " 'hour': 2,\n",
       " 'day': 3,\n",
       " 'month': 4}"
      ]
     },
     "execution_count": 12, 
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_user = dict(test_df[['user','city','state','gender','age','occupation','hour','day','month']].iloc[0])\n",
    "test_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13, 
   "id": "316ec884-f22f-48f0-86ff-b493f1f7477e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 predicted movies for user 6040:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(b'858', 4.1739964),\n",
       " (b'527', 4.171351),\n",
       " (b'1198', 4.1335235),\n",
       " (b'260', 4.11469),\n",
       " (b'2762', 4.095013),\n",
       " (b'1250', 4.0942388),\n",
       " (b'912', 4.089125),\n",
       " (b'1193', 4.0867414),\n",
       " (b'2028', 4.0753107),\n",
       " (b'1262', 4.06947)]"
      ]
     },
     "execution_count": 13, 
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_list = retrieval([tf.constant([str(v)]) for k,v in test_user.items() if k in ['user','city','state']])[1].numpy()[0]\n",
    "movies_data = get_movie_features([int(x) for x in movies_list])\n",
    "ranking_input = {k:np.array([v]) for k,v in test_user.items()}\n",
    "ranking_input.update(movies_data)\n",
    "predicted_rating = ranking_model.predict(ranking_input)[0]\n",
    "\n",
    "print(f'Top 10 predicted movies for user {test_user[\"user\"]}:')\n",
    "sorted(zip(movies_list, np.squeeze(predicted_rating)), key=lambda x: x[1], reverse=True)[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
