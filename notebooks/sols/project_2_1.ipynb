{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eab7f108-7ee4-4136-86d6-096225ea784a",
   "metadata": {},
   "source": [
    "# 2.1 Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1, 
   "id": "216525b0-f79a-464b-a6a7-c756562d2ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from statistics import mean\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae08d9d0-1d9c-4cd7-9870-c4e03d632572",
   "metadata": {},
   "source": [
    "Loading training and test data from project #1. We really only need the `rating` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2, 
   "id": "2ea04d01-d7e2-4c37-9528-242c47b38129",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings = pd.read_csv('../local_data/train_data.csv', header=0)['rating']\n",
    "test_ratings = pd.read_csv('../local_data/test_data.csv', header=0)['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d60f36d-05d9-4289-b06d-a786ff8c60bf",
   "metadata": {},
   "source": [
    "To know if a model's RMSE value is any good, we must compare it to a baseline. Below you'll find 4 such baselines, each of these is a naive no-brainer technique which requires zero effort. If the RMSE of our model is not lower than the baselines, our model is of no use. \n",
    "\n",
    "Remeber the RMSE definition: \n",
    "$$ \\sqrt{\\frac{1}{N}\\Sigma_{i=1}^{N}{\\Big(x_i -\\hat{x}_i\\Big)^2}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3, 
   "id": "eca2940a-ad2a-4ee6-93e3-a0da62ef389e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(5, 214936), (4, 331600), (3, 248122), (2, 102148), (1, 53392)])\n"
     ]
    }
   ],
   "source": [
    "def rmse(lst):\n",
    "    return sqrt(mean([pow(x - float(r), 2.) for x,r in zip(lst, test_ratings)]))\n",
    "\n",
    "ratings = Counter(train_ratings).items()\n",
    "print(ratings)\n",
    "ratings = [(x[0], float(x[1])/sum([z[1] for z in ratings])) for x in ratings]\n",
    "np.random.choice([x[0] for x in ratings], p=[x[1] for x in ratings])\n",
    "num_of_predictions = len(test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4, 
   "id": "57e4d23e-d854-466f-adf1-0186925c9a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Baselines:\n",
      "-----\n",
      "Random sampling:\t1.90\n",
      "Weighted sampling:\t1.59\n",
      "Majority class:\t\t1.19\n",
      "Mean value:\t\t1.12\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE Baselines:\\n-----\")\n",
    "print(f\"Random sampling:\\t{rmse(np.random.choice(range(1,6), size=num_of_predictions)):.2f}\")\n",
    "print(f\"Weighted sampling:\\t{rmse(np.random.choice([x[0] for x in ratings],p=[x[1] for x in ratings], size=num_of_predictions)):.2f}\")\n",
    "print(f\"Majority class:\\t\\t{rmse([4.]*num_of_predictions):.2f}\")\n",
    "print(f\"Mean value:\\t\\t{rmse([mean(train_ratings)]*num_of_predictions):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b7b23a-f1e7-4158-97c8-d5bc98c8794f",
   "metadata": {},
   "source": [
    "We see the lowest RMSE we can rach without any trained model is 1.12"
   ]
  },
  {
   "cell_type": "code",
   "id": "13c447cf-0781-4785-a41d-dbafe751f784",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
